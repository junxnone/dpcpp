
# 8 调度内核和数据移动

\begin{center}
	\includegraphics[width=0.3\textwidth]{content/chapter-8/images/1}
\end{center}

我们需要对并行大师进行讨论。编排并行程序是一件美妙的事情——因为把所有数据安排的明明白白，所以代码无需等待就能全速运行。并且代码进行了分解，以保持硬件最大程度的使用。

生活在快车道上——而不仅仅是一条车道!——我们要认真地对待调度工作。为了做到这一点，可以用任务图来规划工作。

本章中，我们将讨论任务图，用于正确有效地运行复杂内核序列的机制。在应用程序中，有两件事情需要排序:内核和数据移动。任务图是我们用来实现正确排序的机制。

首先，快速回顾如何使用依赖项来编排第3章中的任务。接下来，将介绍DPC++运行时如何构建图。我们将讨论DPC++图的基本构造块，即命令组。然后，说明构建图的不同方法。还会讨论数据移动(包括显式和隐式)如何用图表示。最后，将讨论与主机同步图的各种方法。

## 8.1 什么是图调度？

第3章中，我们讨论了数据管理和数据使用的排序。描述了DPC++中图的关键:依赖。内核间的依赖基本上是基于内核所访问的数据。计算输出之前，内核需要确定是否读取了正确的数据。

我们描述了三种类型的数据依赖，它们对于正确执行非常重要。第一种是读后写(RAW)，当一个任务需要读取由另一个任务产生的数据时发生。这种类型的依赖描述了两个内核之间的数据流。第二种依赖发生在一个任务在另一个任务读取数据后需要更新数据时，称之为写后读(WAR)依赖。当两个任务试图写入相同的数据时，就会出现最后一种数据依赖，这就是写后写(WAW)依赖关系。

数据依赖关系是用于构建图的构建块。这组依赖关系是我们所需要的，既可以表示简单的线性链，也可以表示具有复杂依赖关系的大型复杂图。无论计算需要哪种类型的图，DPC++图都能确保程序基于依赖正确执行。然而，开发者必须确保图能正确地表达程序中的所有依赖关系。

## 8.2 DPC++中如何操作图

命令组可以包含三种东西:操作、依赖关系和主机代码。这三样中，必须的是操作。大多数命令组也会有依赖关系，但有些情况下可能不会(比如：程序中提交的第一个操作)，不依赖任何东西来执行，因此不会指定任何依赖关系。在命令组中可能出现的是在主机上执行的C++代码，这可以帮助指定操作或其依赖项，并且在创建命令组时执行此代码。

命令组通常表示为传递给submit的C++ Lambda表达式。命令组还可以通过队列对象上的快捷方法表示，这些队列对象采用了内核和基于事件的依赖项。

\hspace*{\fill}  %插入空行
\textbf{命令组行为}

命令组可以执行两种类型的操作:内核操作和显式内存操作。一个命令组只能执行一个操作。正如前面的章节所示，内核通过调用parallel\_for或single\_task进行定义，并表示在设备上执行的计算。用于显式数据移动的操作是第二种类型的操作。USM包括memcpy、memset和fill操作。缓冲区中包括copy、fill和update\_host。

\hspace*{\fill}  %插入空行
\textbf{命令组如何声明依赖关系}

命令组的另一个主要组成是在执行组定义的操作之前满足的依赖。DPC++允许以多种方式指定这些依赖项。

如果程序使用有序的DPC++队列，队列的有序语义指定了进入队列的命令组之间的隐式依赖关系。在之前的任务完成之前，其他任务不能执行。

基于事件的依赖关系，是指定在执行命令组之前必须完成任务的另一种方法。这些基于事件的依赖项可以通过两种方式指定。将命令组指定为传递给队列的submit的Lambda时，使用第一种方法。这种情况下，开发者调用命令组处理程序对象的depends\_on方法，传递一个事件或事件组作为参数。当从队列对象上定义的快捷方法创建命令组时，使用另一种方法。当开发者直接调用队列上的parallel\_for或single\_task时，一个事件或事件组可以作为参数。

指定依赖项的最后一种方法是通过创建访问器对象。访问器指定如何来读取或写入缓冲区对象中的数据，让运行时使用该信息确定不同内核之间存在的数据依赖关系。如在本章开头的，数据依赖的例子包括:一个内核读取另一个内核生成的数据，两个内核写入相同的数据，或者一个内核在另一个内核读取数据后修改数据。

\hspace*{\fill}  %插入空行
\textbf{示例}

现在用几个例子来说明刚刚学过的东西。我们将介绍如何用几种方式表达两种不同的依赖模式，说明两种模式是线性依赖的，其中一个任务在另一个任务之后执行，以及“Y”模式，其中两个独立的任务必须在后续任务之前执行。.

这些依赖模式的见图8-1和图8-2。图8-1描述了一个线性相关链。第一个节点表示数据的初始化，而第二个节点表示将数据累加为单个结果的归约操作。图8-2描述了一个“Y”模式，其中分别初始化两个不同的数据。数据初始化后，加法内核将两个向量相加。最后，图中的最后一个节点将结果累加为一个值。

\hspace*{\fill}  %插入空行
图8-1 线性相关
\begin{center}
	\includegraphics[width=0.2\textwidth]{content/chapter-8/images/2}
\end{center}

对于每个模式，我们将展示三种不同的实现。第一个实现将使用有序队列，第二个将使用基于事件的依赖项，最后一个实现将使用缓冲区和访问器来表示命令组之间的数据依赖关系。

\hspace*{\fill}  %插入空行
图8-2 “Y”模式依赖
\begin{center}
	\includegraphics[width=0.5\textwidth]{content/chapter-8/images/3}
\end{center}

\hspace*{\fill}  %插入空行
图8-3 具有有序队列的线性依赖链
\begin{lstlisting}[caption={}]
constexpr int N = 42;

queue Q{property::queue::in_order()};

int *data = malloc_shared<int>(N, Q);

Q.parallel_for(N, [=](id<1> i) { data[i] = 1; });

Q.single_task([=]() {
	for (int i = 1; i < N; i++)
		data[0] += data[i];
});

Q.wait();

assert(data[0] == N);
\end{lstlisting}

如图8-3所示，使用有序队列表示线性依赖。这个示例非常简单，因为有序队列的语义可以保证命令组之间的连续执行顺序。提交的第一个内核将数组的元素初始化为1。下一个内核取这些元素，并将它们加起来成为第一个元素。由于队列是有序的，不需要做任何其他事情来表示第二个内核在第一个内核完成之前不应该执行。最后，等待队列完成所有任务，并检查是否获得了预期的结果。

\hspace*{\fill}  %插入空行
图8-4 与事件线性相关
\begin{lstlisting}[caption={}]
constexpr int N = 42;

queue Q;

int *data = malloc_shared<int>(N, Q);

auto e = Q.parallel_for(N, [=](id<1> i) { data[i] = 1; });

Q.submit([&](handler &h) {
	h.depends_on(e);
	h.single_task([=]() {
		for (int i = 1; i < N; i++)
			data[0] += data[i];
	});
});

Q.wait();
assert(data[0] == N);
\end{lstlisting}

图8-4展示了使用无序队列和基于事件依赖的示例。我们捕获第一次调用parallel\_for所返回的事件。然后，第二个内核能够指定对该事件的依赖，并通过将其作为参数传递给depends\_on来表示内核执行。我们将在图8-6中看到如何使用定义内核的快捷方法，来缩短第二个内核的表达式。

\hspace*{\fill}  %插入空行
图8-5 带有缓冲区和访问器的线性依赖
\begin{lstlisting}[caption={}]
constexpr int N = 42;
queue Q;

buffer<int> data{range{N}};

Q.submit([&](handler &h) {
	accessor a{data, h};
	h.parallel_for(N, [=](id<1> i) { a[i] = 1; });
});

Q.submit([&](handler &h) {
	accessor a{data, h};
	h.single_task([=]() {
		for (int i = 1; i < N; i++)
			a[0] += a[i];
	});
});

host_accessor h_a{data};
assert(h_a[0] == N);
\end{lstlisting}

图8-5使用缓冲区和访问器，重写了线性依赖链示例。这里再次使用无序队列，但使用通过访问器指定的数据依赖项，对命令组的执行进行排序。第二个内核读取第一个内核产生的数据，因为基于相同的底层缓冲区对象声明的访问器，所以运行时可以预期相应的操作。这里与前面的示例不同，不需要等待队列完成所有任务。这里使用主机访问器定义了数据之间的依赖关系，并在主机上计算出第二个内核的正确输出，并使用断言来判断内核给出的答案是否正确。请注意，虽然主机访问器提供了主机上数据，但如果在创建缓冲区时指定了原始主机内存，就不能保证已经更新了原始主机内存。除非先销毁缓冲区，或者使用更高级的机制(如第7章中描述的互斥机制)，否则无法安全地访问原始主机内存。

\hspace*{\fill}  %插入空行
图8-6 有序队列的“Y”模式
\begin{lstlisting}[caption={}]
constexpr int N = 42;

queue Q{property::queue::in_order()};

int *data1 = malloc_shared<int>(N, Q);
int *data2 = malloc_shared<int>(N, Q);

Q.parallel_for(N, [=](id<1> i) { data1[i] = 1; });

Q.parallel_for(N, [=](id<1> i) { data2[i] = 2; });

Q.parallel_for(N, [=](id<1> i) { data1[i] += data2[i]; });

Q.single_task([=]() {
	for (int i = 1; i < N; i++)
		data1[0] += data1[i];
	data1[0] /= 3;
});

Q.wait();
assert(data1[0] == N);
\end{lstlisting}

如图8-6所示，使用有序队列表示“Y”模式。本例中，声明了两个数组data1和data2。然后定义两个内核，每个内核将初始化其中一个数组。这些内核并不相互依赖，但是由于队列是有序的，所以内核必须逐个地执行。而且，交换这两个内核的顺序是完全合法的。第二个内核执行之后，第三个内核将第二个数组的元素添加到第一个数组的元素中。最后一个内核函数将第一个数组的元素求和，从而得到与我们在线性相关链的例子中相同的结果。这个求和内核依赖于前面的内核，但是这个线性链也可以让有序队列捕获。最后，等待所有的内核都完成并验证我们是否成功地计算出了“魔数”。

\hspace*{\fill}  %插入空行
图8-7 事件方式的“Y”模式
\begin{lstlisting}[caption={}]
constexpr int N = 42;
queue Q;

int *data1 = malloc_shared<int>(N, Q);
int *data2 = malloc_shared<int>(N, Q);

auto e1 = Q.parallel_for(N, 
			[=](id<1> i) { data1[i] = 1; });

auto e2 = Q.parallel_for(N, 
			[=](id<1> i) { data2[i] = 2; });

auto e3 = Q.parallel_for(range{N}, {e1, e2},
			[=](id<1> i) { data1[i] += data2[i]; });
	
Q.single_task(e3, [=]() {
	for (int i = 1; i < N; i++)
		data1[0] += data1[i];
	data1[0] /= 3;
});

Q.wait();
assert(data1[0] == N);
\end{lstlisting}

图8-7展示了另一种“Y”模式示例，使用了无序队列。由于队列的顺序，依赖关系不再是隐式的，因此必须使用事件显式地指定命令组之间的依赖关系。如图8-6所示，首先定义两个没有初始依赖关系的独立内核。用两个事件来表示这些内核，e1和e2。们定义第三个内核时，必须指定它依赖于前两个内核。这样做是因为依赖于事件e1和e2在执行之前完成。本例中使用快捷形式来指定这些依赖项，而不是处理程序的depends\_on方法。将事件作为参数传递给parallel\_for。想要一次传递多个事件，所以使用接受事件组的形式。幸运的是，现代C++可以通过表达式\{e1, e2\}，将其转换为适当的向量，简化了步操作。

\hspace*{\fill}  %插入空行
图8-8 访问器的“Y”模式
\begin{lstlisting}[caption={}]
constexpr int N = 42;
queue Q;

buffer<int> data1{range{N}};
buffer<int> data2{range{N}};

Q.submit([&](handler &h) {
	accessor a{data1, h};
	h.parallel_for(N, [=](id<1> i) { a[i] = 1; });
});

Q.submit([&](handler &h) {
	accessor b{data2, h};
	h.parallel_for(N, [=](id<1> i) { b[i] = 2; });
});

Q.submit([&](handler &h) {
	accessor a{data1, h};
	accessor b{data2, h, read_only};
	h.parallel_for(N, [=](id<1> i) { a[i] += b[i]; });
});

Q.submit([&](handler &h) {
	accessor a{data1, h};
	h.single_task([=]() {
		for (int i = 1; i < N; i++)
			a[0] += a[i];
		a[0] /= 3;
	});
});

host_accessor h_a{data1};
assert(h_a[0] == N);
\end{lstlisting}

如图8-8所示，最后一个例子中，再次用缓冲区和访问器替换USM指针和事件。这个例子将两个数组data1和data2表示为缓冲区对象。内核不再使用快捷方法，因为必须将访问器与命令组处理程序关联起来。同样，第三个内核必须了解对前两个内核的依赖关系，这里通过为缓冲区声明访问器来完成。因为之前已经为这些缓冲区声明了访问器，所以运行时能够正确地排列这些内核的执行顺序。此外，当声明访问器b时，还向运行时提供了信息。添加了访问标记read\_only，让运行时知道只读取该数据。正如线性依赖的缓冲区和访问器示例中所示，最终的内核通过更新第三个内核产生的值来对自身排序。通过声明主机访问器来获取计算的最终值，该访问器将等待最终内核完成执行，然后将数据移回主机，在那里可以读取数据，并断言内核是否计算出了正确的结果。 

\hspace*{\fill}  %插入空行
\textbf{CG的各个部分是什么时候执行的?}

因为任务图是异步的，所以知道命令组究竟是什么时候执行是有意义的。目前为止，只要满足了内核的依赖关系，就可以执行内核，但是命令组的主机部分会发生什么呢?

当命令组提交到队列时，会立即在主机上执行(在submit返回之前)。命令组的主机部分只执行一次，在命令组中定义的任何内核或显式数据操作，都将排队在设备上执行。


## 8.3 数据传送

数据移动是DPC++图的另一个重点，它对于理解应用程序性能至关重要。数据移动在程序中隐式地发生(使用缓冲区和访问器或使用USM共享分配)，常常会忽略。接下来，我们将研究数据移动在DPC++中影响图执行的不同方式。

\hspace*{\fill}  %插入空行
\textbf{显式}

显式数据移动的优点是会显式地出现在图中，使开发者可以清楚地看到图中发生了什么。我们把显式数据操作分为用于USM的和用于缓冲区的。

如在第6章，当需要在设备内存和主机内存间复制数据时，USM中的显式数据移动就会发生，可以通过memcpy完成。提交操作或命令组将返回一个事件，该事件可用于与其他命令组对操作进行排序。

通过调用命令组处理程序对象的copy或update\_host，将发生缓冲区的显式数据移动。复制方法可用于在主机内存和设备上的访问器对象之间交换数据，一个简单的例子是检查一个长时间运行的计算序列。使用copy的话，数据可以以单向方式从设备写入到主机内存中。如果是使用缓冲区完成的，大多数情况下(例如，不是以use\_host\_ptr创建的)将要求数据首先复制到主机，然后从缓冲区的内存到所需的主机内存。

update\_host是一种非常特殊的复制形式。如果基于主机内存创建了缓冲区，则此方法将把访问器表示的数据复制回原始主机内存。如果程序手动将主机数据与use\_mutex属性创建的缓冲区同步，那么这个操作将非常有用。但是，这种用例不太可能出现在大多数的程序中。

\hspace*{\fill}  %插入空行
\textbf{隐式}

隐式数据移动可能对DPC++中的命令组和任务图产生隐藏的效果。通过隐式数据移动，数据可以通过DPC++运行时或某种硬件和软件的组合在主机和设备之间复制。这两种情况下，复制不需要显式进行。让我们再次分别看看USM和缓冲区的例子。

对于USM，隐式数据移动发生在主机和共享内存中。主机内存并没有真正移动数据，而是远程访问数据，共享内存可能在主机和设备之间迁移。由于这种迁移是自动进行的，所以对于USM隐式数据移动和命令组实际上没有什么需要考虑的。然而，共享内存有一些微妙之处值得了解。

预取操作以类似于memcpy的方式工作，以便让运行时在内核尝试使用共享分配之前开始迁移。然而，与memcpy不同，数据必须复制才能确保结果正确，预取通常视为运行时提高性能的提示，预取不会使内存中的指针值失效。如果预取在内核开始执行之前没有完成，程序仍会正确执行，因为预取并不是一个功能需求，所以很多代码可能会选择使图中的命令组不依赖于预取操作。

缓冲区也有一些细微差别。使用缓冲区时，命令组必须为指定如何使用数据的缓冲区构造访问器。这些数据依赖关系表示了不同命令组之间的顺序，并允许构建任务图。然而，带有缓冲区的命令组有时会进行另外的操作:指定数据移动。

访问器指定内核将读取或写入缓冲区。由此得出的结论是，设备上的数据必须可用，如果不可用，运行时必须在内核开始执行之前将其移到设备上。因此，DPC++运行时必须跟踪当前缓冲区位置，以便安排数据移动操作。访问器在图中创建了一个隐藏节点。如果数据移动是必需的，运行时必须先执行。这样，提交的内核才能正常执行。

再看看图8-8。这个例子中，前两个内核将需要将缓冲区data1和data2复制到设备中，运行时隐式地创建图节点来执行数据移动。当提交第三个内核的命令组时，这些缓冲区可能仍然在设备上，因此运行时将不需要执行数据移动。第四个内核的数据也可能不需要数据移动，但是主机访问器的创建需要运行时在访问器可用之前将缓冲区data1移动回主机。

## 8.4 与主机同步

我们将讨论的最后一个主题是，如何同步图和主机执行。本章中已经涉及到这一点，但现在将研究程序实现这一点的方法。

主机同步的第一个方法是:等待队列。队列对象有两个方法，wait和wait\_and\_throw，阻塞执行，直到提交到队列的每个命令组都完成。非常简单的方法，可以处理许多常见的情况。然而，这种方法是粒度非常粗。如果需要更细粒度的同步，需要使用另一种方法。

主机同步的另一种方法是对事件进行同步。这比在队列上同步更灵活，因为只允许程序在特定的操作或命令组上同步。这可以通过在事件上调用wait方法或在事件类上调用wait来完成，wait可以接受一个事件组。

图8-5和图8-8中使用了不同的方法:主机访问器。主机访问器执行两个功能。首先，使主机上的数据可用。其次，通过在当前访问的图和主机之间定义依赖关系来与主机同步。这可以确保复制回主机的数据是图计算的正确结果。但是，如果缓冲区是由主机内存构造，那么这个原始内存不能保证数值的一致性。

注意，主机访问器是阻塞的。在数据可用之前，主机上的执行可能不会在创建主机访问器之后继续。同样，当主机访问器存在并保持其数据可用时，不能在设备上使用缓冲区。一种常见的模式是在C++作用域中创建主机访问器，以便在不再需要主机访问器时释放数据。这是另一种主机同步的方法。

DPC++中的某些对象在销毁和调用其析构函数时具有特殊行为。当缓冲区和图像销毁或离开生命周期时，也有特殊的行为。当缓冲区销毁时，将等待所有使用该缓冲区的命令组完成执行。当任何内核或内存操作不再使用缓冲区，运行时必须将数据复制回主机。如果缓冲区使用主机指针初始化，或者主机指针传递给set\_final\_data，则会发生复制。然后，运行时库将复制该缓冲区的数据，并在销毁对象之前更新主机内存。

与主机同步的最后一个选项涉及在第7章中描述的一个不常见的特性。回想一下，缓冲区对象的构造函数可选地接受属性列表。创建缓冲区时，传递的属性是use\_mutex。当以这种方式创建缓冲区时，增加了一个要求，即该缓冲区的内存可以与主机程序共享。对该内存的访问由互斥锁控制，当可以安全地访问与缓冲区共享内存时，主机能够获得锁。如果无法获得锁，用户可能需要将内存移动操作排队，以便与主机同步数据。这种用法非常小众，在大多数DPC++应用程序中不太能看到。


## 8.5 总结
本章中，我们学习了图，以及如何在DPC++中构建、调度和执行图。详细介绍了什么是命令组，它的作用是什么。讨论了命令组中可以包含的三种内容:依赖关系、操作和主机代码。回顾了如何使用事件，以及通过访问器描述的数据依赖来指定任务之间的依赖关系。了解到命令组中的单个操作可以是内核操作，也可以是显式内存操作，然后看了几个示例，展示了构建执行图的不同方法。接下来，回顾了数据移动是如何成为DPC++图的重要部分，并了解了数据移动如何显式或隐式地出现在图中。最后，了解了与主机同步执行图的所有方法。

理解程序流程可使我们理解在运行失败时，打印的调试信息。第13章“调试运行时失败”一节中有一个表，根据我们在本书中所获得的知识，这个表会更有意义一些。然而，本书并不打算详细讨论这些编译器的高级信息。

希望了解完这章，可以让您觉得自己是一个执行图专家，可以构建复杂的图，从线性链到具有数百个节点、复杂数据和任务依赖的巨大执行图!下一章中，我们将开始深入研究在特定设备上改进应用程序性能的底层细节。