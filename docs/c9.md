# 9 通信和同步

\begin{center}
	\includegraphics[width=0.3\textwidth]{content/chapter-9/images/1}
\end{center}

第4章中，讨论了表达并行性的方法，包括使用数据并行内核、ND-Range内核或分层并行内核。讨论了数据并行内核如何将相同的操作应用到每一块数据上。还讨论了ND-Range内核和分层并行内核如何划分工作组中的工作项。\par

本章提供了关于ND-Range内核和分层并行内核的更多细节，并描述了如何使用工作项分组来提高算法的性能。描述工作项/组如何并行工作，以及如何执行提供保证，并且引入支持工作项/组的特性。在第15、16、17章中针对特定设备进行优化时，以及在第14章中介绍常见的并行模式，这些思想和概念都非常重要。\par

## 9.1 工作组和工作项

ND-Range和分层并行内核将工作项组织到工作组中，并且工作组中的工作项可以并发执行。工作项可以保证并发时，工作组中的中的协作问题才能解决。\par

\hspace*{\fill} \par %插入空行
图9-1 二维ND-Range中(8,8)个工作项分为四个(4,4)工作组
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/2}
\end{center}

图9-1将ND-Range划分为不同的工作组，每个工作组用不同的颜色表示。工作组中的工作项可以同时执行，因此工作项可以与相同颜色的工作项通信。\par

因为不同工作组不能保证并发执行，所以同一种颜色的工作项不能与不同颜色的工作项通信，并且如果一个工作项试图与当前未执行的另一个工作项通信，可能会导致死锁。当我们希望内核完成执行，必须确保当工作项之间通信时，必须在同一个工作组中。

## 9.2 有效通讯的基础

本节介绍了提供组中工作项间通信的构建块。一些基本的构建块，可以构建自定义算法，而另一些高级别的，则描述了许多内核的常规操作。\par

\hspace*{\fill} \par %插入空行
\textbf{通过栅栏进行同步}

通讯最基本的部分是栅栏功能。栅栏功能有两个目的:\par

首先，栅栏功能可以同步组中工作项的执行。通过同步，工作项可以确保另一个工作项在使用该操作的结果之前完成操作。在另一个工作项使用操作的结果之前，让工作项完成操作。\par

其次，栅栏函数同步每个工作项，并检查内存状态。这种类型的同步操作称为强制内存一致或隔离内存(详见第19章)。内存一致与同步执行一样重要，因为在栅栏前执行的内存操作对栅栏之后执行的其他工作项可见。如果没有内存一致性，工作项中的操作就像森林中倒下的一棵树，其他工作项不一定听得到声音!\par

图9-2显示了在栅栏功能上同步组中的四个工作项。尽管每个工作项的执行时间可能不同，但没有任何工作项可以跨过栅栏执行，直到所有工作项都遇到了栅栏。执行栅栏功能之后，所有工作项就有了一致的内存。\par

\hspace*{\fill} \par %插入空行
图9-2 组中的四个工作项在栅栏功能上的同步
\begin{center}
	\includegraphics[width=0.6\textwidth]{content/chapter-9/images/3}
\end{center}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=为什么内存在默认情况下不一致?]
对于许多开发者来说，内存一致性的概念——以及不同的工作项可以看到不同的内存数据——可能感觉非常奇怪。如果默认情况下所有工作项的所有内存都是一致的，不是更容易吗?是的，但实现的代价非常昂贵。允许工作项看到不一致的内存数据，并且只要求程序执行期间定义的点上保证内存一致性，这样加速器硬件价格会更便宜，性能更好。
\end{tcolorbox}

因为栅栏功能同步执行，所以要么组中的所有工作项执行栅栏操作，要么组中没有工作项执行栅栏操作。如果组分支中的某些工作项绕过栅栏功能，则组中的其他工作项可能永远在栅栏处等待!\par

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=集合功能]
当一个功能需要由组中的所有工作项执行时，可以将其称为集合功能，因为操作由工作组执行，不由组中的单个工作项执行。栅栏函数并不是SYCL中唯一可用的集合函数。本章稍后将介绍其他集合功能。
\end{tcolorbox}

\hspace*{\fill} \par %插入空行
\textbf{工作组的本地内存}

工作组栅栏功能可以协调工作组中工作项的通信，但是通信必须通过内存进行。通信可以通过USM或缓冲区进行，但这可能效率低下:需要为通讯开辟专用内存，并需要在工作组之间进行分配。\par

为了简化内核开发，并加速工作组中工作项的通信，SYCL定义了专用于工作组中工作项之间通信的本地内存。\par

\hspace*{\fill} \par %插入空行
图9-3 每个工作组可以访问所有全局内存，但只能访问自己的本地内存
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/4}
\end{center}

如图9-3所示，两个工作组可以访问全局内存空间中的USM和缓冲区。每个工作组可以访问自己的本地内存中的变量，但不能访问另一个工作组的本地内存中的变量。\par

当一个工作组开始时，其本地内存的内容未初始化，并且本地内存在工作组执行完毕后不会持续存在。由于这些属性，本地内存只能在工作组执行时作为临时存储使用。\par

对于某些设备，本地内存是一种抽象概念，使用与全局内存相同的内存子系统来实现。设备上使用本地内存，主要是以便通信机制的使用。一些编译器可能会使用内存空间信息进行编译器优化；否则，设备上使用本地内存进行通信，并不会比通过全局内存进行通信的性能更好。\par

对于其他设备，比如：多GPU设备，有专用的本地内存资源。这些设备上，通过本地内存通信比通过全局内存通信性能更好。\par

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
使用本地内存时，工作组内部的通信可以更方便、更快捷!
\end{tcolorbox}

可以使用设备查询info::device::local\_mem\_type来确定加速器是否为本地内存提供了专用资源，或者本地内存是否实现为全局内存。有关查询设备属性的更多信息请参见第12章，有关本地内存如何为CPU、GPU和FPGA实现的更多信息详见第15、16和17章。

## 9.3 使用工作组栅栏和本地内存

现在已经确定了工作项之间通信的基本构建块，可以描述如何在内核中表示工作组栅栏和本地内存。记住，工作项之间的通信需要工作组的概念，因此这些概念只能在ND-Range内核和分层内核中表示。\par

本章将以第4章中介绍的矩阵乘法内核示例为基础，通过介绍执行矩阵乘法的工作组中工作项之间的通信。在许多设备上——不一定是所有设备!——通过本地内存通信提高矩阵乘法内核的性能。\par

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=关于矩阵乘法的注意事项]
本书中，矩阵乘法内核用于演示内核的变化如何影响性能。尽管使用本章的技术可以在某些设备上提高矩阵乘法的性能，但鉴于矩阵乘法是非常常见的操作，以至于许多供应商已经实现了矩阵乘法的高度优化版本。厂商投入大量的时间和精力来实现和验证特定设备的功能，并且在某些情况下会使用在标准并行内核中难以或不可能使用的功能或技术。
\end{tcolorbox}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=使用供应商提供的库!]
当供应商提供函数的库实现时，尽可能使用它，而不是将函数重新实现!对于矩阵乘法，可以将oneMKL作为DPC++英特尔oneAPI解决方案工具包的一部分。
\end{tcolorbox}

图9-4展示了第4章的矩阵乘法内核代码。\par

\hspace*{\fill} \par %插入空行
图9-4 第4章中的矩阵乘法内核
\begin{lstlisting}[caption={}]
h.parallel_for(range{M, N}, [=](id<2> id) {
	int m = id[0];
	int n = id[1];
	
	T sum = 0;
	for (int k = 0; k < K; k++)
		sum += matrixA[m][k] * matrixB[k][n];
		
	matrixC[m][n] = sum;
});
\end{lstlisting}

第4章中，我们注意到矩阵乘法算法具有高度的重用性，并且对工作项进行分组可以改善访问的局部性，从而提高缓存命中率。本章中，修改后的矩阵乘法内核将使用本地内存作为缓存，以保证访问的局部性，而不是依赖缓存来提高性能。\par

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
对于许多算法来说，可以将本地内存看作缓存。
\end{tcolorbox}

图9-5是第4章修改后的代码，展示了由单行组成的工作组，这使得使用本地内存的算法更容易理解。注意，对于结果矩阵一行中的元素，每个结果元素都是使用来自一个输入矩阵的数据列计算，用蓝色和橙色显示。因为这个输入矩阵没有数据共享，所以不是理想的本地内存候选。但是，该行中的每个结果元素都访问另一个输入矩阵(绿色部分)中的完全相同的数据。由于此数据是重用的，是工作组本地内存中最佳的方式。\par

\hspace*{\fill} \par %插入空行
图9-5 矩阵乘法中工作组和工作项的映射
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/5}
\end{center}

因为要将非常大的矩阵相乘，而且工作组本地内存可能是有限的资源，所以修改后的内核将处理每个矩阵的子部分，将其称为矩阵块。对于每个块，修改后的内核将把矩阵块的数据加载到本地内存中，同步组中的工作项，然后从本地内存而不是全局内存加载数据。第一个块所访问的数据如图9-6所示。\par

内核中选择了与工作组大小相等的块大小。这不是必需的，但简化了本地内存的数据传输，所以块的大小通常可以选择工作组大小的倍数。\par

\hspace*{\fill} \par %插入空行
图9-6 处理第一个块:绿色的输入数据(X的左边)重用并从本地内存读取，蓝色和橙色的输入数据(X的右边)从全局内存读取
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/6}
\end{center}

\hspace*{\fill} \par %插入空行
\textbf{ND-Range内核中的工作组栅栏和本地内存}

本节描述如何在ND-Range内核中表示工作组栅栏和本地内存。对于ND-Range内核:内核声明并操作本地地址空间分配的本地访问器，调用栅栏函数来同步工作组中的工作项。\par

\hspace*{\fill} \par %插入空行
\textbf{本地内存访问器}

要声明在ND-Range内核中使用的本地内存，请使用本地访问器。与其他访问器一样，本地访问器在命令组处理程序中构造，但与第3章和第7章讨论的访问器对象不同，本地访问器不是从缓冲区对象创建的。可以通过指定类型和描述该类型元素数量的范围来创建本地访问器。与其他访问器一样，本地访问器可以是1维、2维或3维的。图9-7演示了如何声明本地访问器并在内核中使用。\par

本地内存在每个工作组开始时未初始化，每个工作组完成后不会持续保存数据。这意味着本地访问器必须是read\_write，否则内核将无法分配本地内存的内容或查看分配的结果。但本地访问器可以选择为原子的，可以通过访问器对本地内存进行原子访存。原子访存将在第19章进行更详细的讨论。\par

\hspace*{\fill} \par %插入空行
图9-7 声明和使用本地访问器
\begin{lstlisting}[caption={}]
// This is a typical global accessor.
accessor dataAcc {dataBuf, h};

// This is a 1D local accessor consisting of 16 ints:
local_accessor<int> localIntAcc{16, h};

// This is a 2D local accessor consisting of 4 x 4 floats:
local_accessor<float,2> localFloatAcc{{4,4}, h};

h.parallel_for(nd_range<1>{{size}, {16}}, [=](nd_item<1> item) {
	auto index = item.get_global_id();
	auto local_index = item.get_local_id();
	
	// Within a kernel, a local accessor may be read from
	// and written to like any other accessor.
	localIntAcc[local_index] = dataAcc[index] + 1;
	dataAcc[index] = localIntAcc[local_index];
});
\end{lstlisting}

\hspace*{\fill} \par %插入空行
\textbf{同步功能}

同步ND-Range内核工作组中的工作项，可以使用nd\_item类中的barrier函数。因为barrier函数是nd\_item类的成员，所以只对ND-Range的内核可用，而对简单的数据并行内核或分层内核不可用。\par

barrier函数目前接受一个参数来描述要同步的内存空间，但是barrier函数的参数将来可能会随着SYCL和DPC++中内存模型的发展而改变。但是，barrier函数的参数提供了关于同步内存空间或内存同步域的控制。\par

当没有参数传递给barrier函数时，barrier函数将使用功能上正确和默认值。本章中的代码示例使用了这种方式，以获得最大的可移植性和可读性。对于高度优化的内核，建议精确地描述哪些内存空间或哪些工作项必须同步，这可能会提高性能。\par

\hspace*{\fill} \par %插入空行
\textbf{完整的ND-Range内核示例}

现在知道了如何声明本地内存访问器并使用barrier函数同步对它的访问，可以实现矩阵乘法的ND-Range内核版本，协调工作组中工作项之间的通信，以减少对全局内存的通信。完整示例如图9-8所示。\par

\hspace*{\fill} \par %插入空行
图9-8 用ND-range parallel\_for和工作组本地内存表示块矩阵乘法内核
\begin{lstlisting}[caption={}]
// Traditional accessors, representing matrices in global memory:
accessor matrixA{bufA, h};
accessor matrixB{bufB, h};
accessor matrixC{bufC, h};

// Local accessor, for one matrix tile:
constexpr int tile_size = 16;
local_accessor<int> tileA{tile_size, h};

h.parallel_for(
nd_range<2>{{M, N}, {1, tile_size}}, [=](nd_item<2> item) {
	// Indices in the global index space:
	int m = item.get_global_id()[0];
	int n = item.get_global_id()[1];
	
	// Index in the local index space:
	int i = item.get_local_id()[1];
	
	T sum = 0;
	for (int kk = 0; kk < K; kk += tile_size) {
		// Load the matrix tile from matrix A, and synchronize
		// to ensure all work-items have a consistent view
		// of the matrix tile in local memory.
		tileA[i] = matrixA[m][kk + i];
		item.barrier();
		
		// Perform computation using the local memory tile, and
		// matrix B in global memory.
		for (int k = 0; k < tile_size; k++)
			sum += tileA[k] * matrixB[kk + k][n];
		
		// After computation, synchronize again, to ensure all
		// reads from the local memory tile are complete.
		item.barrier();
	}

	// Write the final result to global memory.
	matrixC[m][n] = sum;
});
\end{lstlisting}

这个内核中的主循环可以看作两个不同的阶段:第一个阶段，组中工作项将共享数据从A矩阵加载到本地内存中；第二种情况下，工作项使用共享的数据执行自己的计算。为了确保所有工作项在进入第二个阶段之前已经完成了第一阶段，需要使用barrier来同步所有工作项，并提供内存栅栏来分隔。这种模式很常见，内核中使用工作组本地内存总是需要使用工作组栅栏。\par

注意，还必须调用barrier来同步当前块的计算阶段和下一个矩阵块的加载阶段之间的操作。如果没有此同步操作，则在用另一个工作项完成计算之前，工作组中的工作项结果可能会覆盖当前结果矩阵块的结果。当工作项在本地内存中读写由另一个工作项读写的数据时，就需要同步。图9-8中，同步是在循环结束时完成的，在每个循环开始时也需要同步。\par

\hspace*{\fill} \par %插入空行
\textbf{分层内核中的工作组栅栏和本地内存}

本节描述如何在分层内核中表示工作组栅栏和本地内存。与ND-Range内核不同，分层内核中的本地内存和栅栏是隐式的，不需要特殊的语法或函数调用。一些开发者会发现分层内核表示更直观、更容易使用，而其他开发者会喜欢ND-Range内核提供的直接控制。大多数情况下，相同的算法可能使用两种表示来描述，因此可以选择最容易开发和维护的方式。\par

\hspace*{\fill} \par %插入空行
\textbf{本地内存和栅栏的作用域}

回顾第4章，分层内核通过使用parallel\_for\_work\_group和parallel\_for\_work\_item来表示两级的并行执行。并行执行的这两个级别(或作用域)用于表示变量是否位于工作组本地内存中，并在工作组中的所有工作项之间共享，或者变量是否位于每个工作项的私有内存中(不在工作项之间共享)。这两个作用域还用于同步工作组中的工作项，并强制内存一致性。\par

图9-9展示了一个层次结构内核，在本地内存中声明一个在工作组作用域的变量，然后在工作项作用域中使用该变量。在工作组作用域对本地内存的写入和工作项作用域对本地内存的读取之间存在隐式的栅栏。\par

\hspace*{\fill} \par %插入空行
图9-9 具有局部内存变量的分层内核
\begin{lstlisting}[caption={}]
range group_size{16};
range num_groups = size / group_size;

h.parallel_for_work_group(num_groups, group_size, [=](group<1> group) {
	// This variable is declared at work-group scope, so
	// it is allocated in local memory and accessible to
	// all work-items.
	int localIntArr[16];
	
	// There is an implicit barrier between code and variables
	// declared at work-group scope and the code and variables
	// at work-item scope.
	
	group.parallel_for_work_item([&](h_item<1> item) {
		auto index = item.get_global_id();
		auto local_index = item.get_local_id();
		
		// The code at work-item scope can read and write the
		// variables declared at work-group scope.
		localIntArr[local_index] = index + 1;
		data_acc[index] = localIntArr[local_index];
	});
});
\end{lstlisting}

分层内核的主要优点是，看起来非常类似于标准C++代码，标准C++代码中，一些变量可以在作用域中赋值，并在嵌套作用域中使用。当然，这也可以认为是一种缺点，因为哪些变量在本地内存中，以及什么时候由分层内核编译器插入栅栏，这些都不是很明显。对于实现栅栏操作非常昂贵的设备来说尤其如此!\par

\hspace*{\fill} \par %插入空行
\textbf{完整的分层内核示例}

既然知道了如何在分层内核中表示本地内存和栅栏，就可以编写一个分层内核，可以实现与图9-7中的ND-Range内核相同的算法，如图9-10所示。\par

尽管分层内核与ND-Range内核非常相似，但有一个关键的区别:ND-Range内核中，矩阵乘法的结果在写入到内存中的输出矩阵之前累积到每个工作项变量和中，而分层内核则累积到内存中。也可以在分层内核中积累为每个工作项变量，但这需要特殊的private\_memory在工作组作用域声明每个工作项数据，而选择使用分层内核语法的原因之一是避免使用特殊语法!\par

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
分层内核不需要特殊的语法来声明工作组本地内存中的变量，但是需要特殊的语法来声明工作项私有内存中的一些变量!
\end{tcolorbox}

为了避免每个工作项的特殊数据语法，分层内核中工作项循环的常见模式是将中间结果写入工作组本地内存或全局内存。\par

\hspace*{\fill} \par %插入空行
图9-10 块矩阵乘法内核作为分层内核实现
\begin{lstlisting}[caption={}]
const int tileSize = 16;
range group_size{1, tileSize};
range num_groups{M, N / tileSize};

h.parallel_for_work_group(num_groups, group_size, [=](group<2> group) {
	// Because this array is declared at work-group scope
	// it is in local memory
	T tileA[16];
	
	for (int kk = 0; kk < K; kk += tileSize) {
		// A barrier may be inserted between scopes here
		// automatically, unless the compiler can prove it is
		// not required
		
		// Load the matrix tile from matrix A
		group.parallel_for_work_item([&](h_item<2> item) {
			int m = item.get_global_id()[0];
			int i = item.get_local_id()[1];
			tileA[i] = matrixA[m][kk + i];
		});
	
		// A barrier gets inserted here automatically, so all
		// work items have a consistent view of memory
		
		group.parallel_for_work_item([&](h_item<2> item) {
			int m = item.get_global_id()[0];
			int n = item.get_global_id()[1];
			for (int k = 0; k < tileSize; k++)
			matrixC[m][n] += tileA[k] * matrixB[kk + k][n];
		});
	
		// A barrier gets inserted here automatically, too
	}
});
\end{lstlisting}

图9-10中内核有一个有趣的属性与循环变量kk有关:由于循环处于工作组作用域，循环迭代变量kk可以从工作组本地内存中分配，就像tileA数组一样。由于kk的值对于工作组中的所有工作项都是相同的，所以编译器可能会选择在每个工作项内存中分配kk，特别是对于本地内存稀缺的设备。

## 9.4 子工作组

目前为止，工作项已经通过工作组本地内存交换数据，并通过隐式或显式barrier函数进行同步(这取决于内核是如何编写的)，与工作组中的其他工作项进行了通信。\par

第4章中，讨论了另一种工作项分组。子工作组是工作组中定义子工作集，在相同的硬件资源或调度上一起执行。因为实现决定如何将工作项分组到子工作组中，子工作组中的工作项可能比任意工作组中的工作项更有效地通信或同步。\par

本节描述子工作组中工作项之间通信的构建块。注意，子工作组目前仅为ND-Range内核实现，并且子工作组不能通过分层内核表示。\par

\hspace*{\fill} \par %插入空行
\textbf{同步操作与子工作组的栅栏}

就像ND-Range内核中工作组中的工作项，可以使用工作组barrier功能进行同步，子工作组中的工作项可以使用子工作组栅栏功能进行同步。工作组同步可以通过调用工作项group\_barrier或nd\_item类的barrier功能完成。子工作组中的工作项的同步，是通过调用group\_barrier函数或sub\_group类上的barrier函数(可使用nd\_item类查询)，如图9-11。\par

\hspace*{\fill} \par %插入空行
图9-11 查询和使用sub\_group类
\begin{lstlisting}[caption={}]
h.parallel_for(nd_range{{size}, {16}}, [=](nd_item<1> item) {
	auto sg = item.get_sub_group();
	...
	sg.barrier();
	...
});
\end{lstlisting}

像工作组栅栏一样，子工作组的栅栏可以接受参数，来更精确地控制栅栏操作。无论子工作组栅栏功能是同步全局内存还是本地内存，只同步子工作组中的工作项，都可能比同步工作组中的所有工作项要划算。\par

\hspace*{\fill} \par %插入空行
\textbf{子工作组内的数据交换}

与工作组不同，子工作组没有用于交换数据的专用内存空间。子工作组中的工作项可以通过工作组的本地内存、全局内存或通过使用子工作组集合函数来交换数据。\par

如前所述，集合功能是描述由一组工作项执行的操作的功能，而不是单个工作项，并且因为栅栏同步功能是由一组工作项执行的操作，所以是集合功能。\par

其他集合功能表示公共通信模式。我们将在本章后面详细描述许多集合函数，现在简要描述广播集合函数，将使用子工作组来实现矩阵乘法。\par

广播集合函数从组中的一个工作项中获取值，并将其传递给组中的所有其他工作项，配置示例如图9-12所示。注意，广播函数的语义要标识组中哪个值要通信的local\_id对于组中的所有工作项必须相同，以确保广播函数的结果对于组中的所有工作项是相同的。\par

\hspace*{\fill} \par %插入空行
图9-12 广播功能
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/7}
\end{center}

如果查看本地内存矩阵乘法内核的最内层循环，如图9-13所示，可以看到对矩阵块的访问是一个广播操作，因为组中的每个工作项从矩阵块中读取相同的值。\par

\hspace*{\fill} \par %插入空行
图9-13 包含广播操作的矩阵乘法内核
\begin{lstlisting}[caption={}]
h.parallel_for<class MatrixMultiplication>(
	nd_range<2>{ {M, N}, {1, tileSize} }, [=](nd_item<2> item) {
	...
	
	// Perform computation using the local memory tile, and
	// matrix B in global memory.
	for( size_t k = 0; k < tileSize; k++ ) {
		// Because the value of k is the same for all work-items
		// in the group, these reads from tileA are broadcast
		// operations.
		sum += tileA[k] * matrixB[kk + k][n];
	}
	...
});
\end{lstlisting}

使用子组广播功能来实现不需要工作组本地内存或栅栏的矩阵乘法内核。许多设备上，子工作组广播比使用工作组本地内存和栅栏的广播更快。\par

\hspace*{\fill} \par %插入空行
\textbf{完整的子组ND-Range内核示例}

图9-14使用子工作组实现矩阵乘法的完整示例。注意，此内核不需要工作组本地内存或显式同步，而是使用子工作组广播集合函数在工作项之间通信矩阵块的内容。\par

\hspace*{\fill} \par %插入空行
图9-14 用NDrange parallel\_for和子组集合函数表示块矩阵乘法内核
\begin{lstlisting}[caption={}]
// Note: This example assumes that the sub-group size is 
// greater than or equal to the tile size!
static const int tileSize = 4;

h.parallel_for(
nd_range<2>{{M, N}, {1, tileSize}}, [=](nd_item<2> item) {
	auto sg = item.get_sub_group();
	
	// Indices in the global index space:
	int m = item.get_global_id()[0];
	int n = item.get_global_id()[1];
	
	// Index in the local index space:
	int i = item.get_local_id()[1];
	
	T sum = 0;
	for (int_fast64_t kk = 0; kk < K; kk += tileSize) {
		// Load the matrix tile from matrix A.
		T tileA = matrixA[m][kk + i];
		
		// Perform computation by broadcasting from the matrix
		// tile and loading from matrix B in global memory. The loop
		// variable k describes which work-item in the sub-group to
		// broadcast data from.
		for (int k = 0; k < tileSize; k++)
			sum += intel::broadcast(sg, tileA, k) * matrixB[kk + k][n];
	}

	// Write the final result to global memory.
	matrixC[m][n] = sum;
});
});
\end{lstlisting}


## 9.5 通用功能

本章的“子工作组”部分，我们描述了集合功能以及集合功能如何表达公共通信模式。我们特别讨论了广播集合功能，它用于将值从组中的一个工作项传递到组中的其他工作项。本节介绍其他集合函数。\par

虽然本节中描述的集合函数，可以在程序中使用原子、工作组本地内存和栅栏等特性直接实现，但许多设备包括专用硬件对集合函数进行了加速。即使设备不包括专门的硬件，供应商提供的集合函数的实现可能针对它们的设备进行调优，因此调用内置集合函数通常会比编写的通用实现执行得更好。\par

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
为公共通信模式使用集合函数来简化代码并提高性能!
\end{tcolorbox}

工作组和子工作组都支持许多集合功能。其他集合功能仅支持子工作组\par

\hspace*{\fill} \par %插入空行
\textbf{广播}

广播功能允许组中的一个工作项与组中其他工作项共享变量的值。广播功能的工作原理如图9-12所示。工作组和子工作组都支持广播功能。\par

\hspace*{\fill} \par %插入空行
\textbf{投票}

any\_of和all\_of功能(今后将共同称为“投票”功能)使组内工作项比较的结果为一个布尔值：至少一个工作项的条件为真时，any\_of返回true；只有在所有工作项的条件为真时，all\_of返回true。对于一个输入示例，这两个函数的比较如图9-15所示。\par

\hspace*{\fill} \par %插入空行
图9-15 比较any\_of函数和all\_of函数
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/8}
\end{center}

工作组和子工作组都支持any\_of和all\_of投票函数。\par

\hspace*{\fill} \par %插入空行
\textbf{打乱}

子工作组最有用的特性之一是能够在单个工作项之间直接通信，而不需要显式的内存操作。许多情况下，例如：子工作组矩阵乘法内核，这些打乱操作使我们能够从内核中删除工作组本地内存的使用和/或避免对全局内存不必要的重复访问。这些打乱函数有几种类型。\par

最通用的打乱函数，称为shuffle，如图9-16所示，它允许子工作组中的任何工作项之间进行通信。然而，这种通用性可能会以性能为代价，我们强烈鼓励尽可能使用更特化的shuffle函数。\par

图9-16中，使用shuffle对预先计算的置换索引对子组的x值进行排序。展示了子工作组中一个工作项的箭头，其中shuffle的结果是local\_id等于7的工作项的x值。\par

\hspace*{\fill} \par %插入空行
图9-16 使用shuffle对预先计算的排列索引对x值排序
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/9}
\end{center}

注意，可以将子工作组广播函数视为shuffle的特化版，其中shuffle索引对于子工作组中的所有工作项是相同的，使用广播而不是shuffle可为编译器提供信息，并可能提高某些实现的性能。\par

shuffle\_up和shuffle\_down函数有效地将子工作组的内容向给定方向移动一定数量元素的长度，如图9-17所示。注意，返回到子工作组中最后五个工作项的值是未定义的，并且在图9-17中显示为空白。对于并行化带有循环依赖的循环，或者在实现扫描等常见算法时，移位非常有用。\par

\hspace*{\fill} \par %插入空行
图9-17 使用shuffle\_down将子组的x值移动5个元素的长度
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/10}
\end{center}

shuffle\_xor函数交换两个工作项的值，这些值由应用于工作项的子工作组本地id和常量的XOR操作结果的的指定。如图9-18和9-19所示，几种常见的通信模式可以用异或表示，例如：交换相邻值对。\par

\hspace*{\fill} \par %插入空行
图9-18 使用shuffle\_xor交换相邻的x对
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/11}
\end{center}

或者反转子工作组的结果。\par

\hspace*{\fill} \par %插入空行
图9-19 使用shuffle\_xor反转x的值
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/12}
\end{center}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=使用优化的广播，投票和集合函数]
应用于子工作组的广播、投票和其他集合函数的行为与应用于工作组的行为是相同的，但是需要注意的是，它们会在某些编译器中启用主动优化，例如：编译器可能能够减少广播到子工作组中所有工作项的变量的寄存器使用，或者能够基于any\_of和all\_of函数的使用推断出控制流的方向。
\end{tcolorbox}

\hspace*{\fill} \par %插入空行
\textbf{加载和存储}

子工作组的加载和存储函数有两个目的:第一，通知编译器子工作组中的所有工作项都从内存中的相同(统一)位置加载连续数据；第二，能够请求优化的加载/存储大量连续数据。\par

对于ND-Range parallel\_for，编译器可能不清楚由不同工作项计算的地址如何关联。例如，如图9-20所示，从每个工作项的角度来看，从索引[0,32)访问一个连续的内存块似乎是跨越的访问模式。\par

\hspace*{\fill} \par %插入空行
图9-20 一个子工作组访问四个连续块的内存
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-9/images/13}
\end{center}

有些体系结构包括专用硬件，用于检测子工作组中的工作项，何时访问连续数据并组合内存请求，而其他体系结构要求提前知道这一点并将其编码到加载/存储指令中。子工作组的加载和存储在任何平台上，都不是为了正确性存在的，但在某些平台上可能会提高性能，应视为一种优化提示。\par


## 9.6 总结

本章讨论了一个组中的工作项如何交流和合作以提高某些类型内核的性能。\par

首先讨论了ND-Range内核和分层内核如何支持将工作项分组到工作组中。讨论了如何将工作项分组到工作组中，从而更改并行执行模型，以确保工作组中的工作项并发执行，并支持通信和同步。\par

接下来，讨论了工作组中的工作项如何使用barrier进行同步，以及如何在ND-Range内核中显式地表示barrier，或者在分层内核的工作组和工作项范围中隐式地表示barrier。还讨论了如何通过工作组本地内存执行工作组中工作项之间的通信，以简化内核并提高性能，以及如何使用用于ND-Range内核的本地访问器来表示工作组本地内存，以及如何使用分层内核工作组范围内的本地内存。\par

讨论了如何将ND-Range内核中的工作组进一步划分为子工作组，其中子工作组可能支持其他的通信模式或调度。\par

对于工作组和子工作组，我们讨论了如何通过使用集合功能来表达和加速公共通信模式。\par

本章中的概念是理解第14章中描述的常见并行模式，以及理解第15、16和17章中如何针对特定设备进行优化的基础。
