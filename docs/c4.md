# 4 并发表示
\begin{center}
	\includegraphics[width=0.5\textwidth]{content/chapter-4/images/1}
\end{center}

现在可以把第一批拼图拼在一起了。了解了如何在设备上执行代码(第2章)和数据(第3章)——现在必须做的就是如何处理它们。为了达到这个目的，现在补充一些容易忽略的东西。本章标志着从教学示例向实际并行代码的转变，会扩展前面章节中的代码示例的细节。

用一种新的并行语言编写第一个程序似乎很困难，特别是对并行编程的新手。语言规范不是为应用程序开发人员编写的，通常需要对术语有所了解:

\begin{itemize}
	\item 为什么会有不止一种表达并行性的方法?
	\item 应该用哪种方法来表达并行性?
	\item 关于执行模型，需要了解多少?
\end{itemize}

本章会解决这些问题和其他问题。我们会了解数据并行内核的概念，使用工作代码示例讨论不同内核形式的优缺点，并重点介绍内核执行模型。


## 4.1 内核间的并行

关于执行模型，需要了解多少?近年来，并行内核作为一种表达数据并行性的方式出现。基于内核的方法主要为了跨各种设备的可移植性，以便提高开发者工作效率。因此，内核通常不是硬编码处理特定数量或配置硬件资源(例如：内核、硬件线程、SIMD[单指令多数据]指令)。相反，内核用抽象的概念来描述并行性，实现(即编译器和运行时的组合)可以映射到特定目标设备上的可用硬件并行。尽管这种映射是由具体实现定义，但我们相信其会选择一种合理，且能够有效利用硬件并行性的映射。

以一种硬件无关的方式运行大量的并行计算，确保了程序可以扩展(或缩小)以适应不同平台的能力，但是……

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
保证功能的可移植性，但不保证高性能!
\end{tcolorbox}

支持的设备很多，不同的架构为不同的用例设计和优化。想要在特定的设备上达到最高的性能水平，总是需要一些手动优化工作——不管使用什么编程语言!这种特定于设备的优化的例子包括针对缓存的阻塞、选择平摊调度开销的粒度大小、使用专门的指令或硬件单元，以及选择适当的算法。其中一些例子将在第15、16和17章中继续讨论。

应用程序开发过程中，在性能、可移植性和生产率之间的平衡是必须面对的挑战，也是本书不能完全解决的挑战。然而，我们希望证明DPC++提供了一种高级编程语言，还提供了可维护通用可移植代码和优化目标特定代码所需的所有工具。

\hspace*{\fill}  %插入空行
\textbf{多维内核}

许多语言的并行构造是1维的，直接将工作映射到1维硬件资源(例如：硬件线程数)。并行内核是一个更高层次的概念，维度更多地反映了代码要解决的问题(在1、2或3维空间中)。

为了在1维空间开发方便，并行内核提供的多维索引。理解这个映射的行为方式可能是某些优化(例如：调优内存访问模式)的重要部分。

需要思考的是，哪个维度是连续的或“单位跨距”(即，多维空间中的数据落在一维空间中的位置)。SYCL中与并行性相关的多维变量都遵循相同的约定:维度从0到N-1进行编号。这种约定与标准C++中多维数组的行为一致。

SYCL将二维空间映射为线性索引的示例如图4-1所示。也可以打破这种方式，采用自己的方法来线性化索引，这样做必须小心——打破惯例可能会对让步长为1访问方式有性能收益的设备产生负面的性能影响。

\hspace*{\fill}  %插入空行
图4-1 映射二维范围(2,8)到线性索引上
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-4/images/2}
\end{center}

如果程序数据大于三个维度，则必须使用模算法手动负责多维索引和线性索引之间的映射。

\hspace*{\fill}  %插入空行
\textbf{循环与内核}

迭代循环是一种串行结构:循环的每次迭代都按顺序执行。优化的编译器可以确定迭代循环的部分或全部是否可以并行执行，但必须是保证，当编译器无法证明并行执行是安全的，则保持循环顺序语义的正确性。

\hspace*{\fill}  %插入空行
图4-2 用串行循环表示向量加法
\begin{lstlisting}[caption={}]
for (int i = 0; i < N; ++i) {
	c[i] = a[i] + b[i];
}
\end{lstlisting}

考虑图4-2中的循环，描述了简单的向量加法。即使在这样的情况下，证明循环可以并行执行也不是一件简单的事情:只有当c不重叠a或b时，并行执行才安全。而在一般情况下，没有运行时检查是无法证明这一点的!为了解决这样的情况，语言添加了一些特性，使我们能够向编译器提供信息，从而简化分析(例如，断言指针不与restrict重叠)或完全覆盖所有情况进行分析(例如，声明循环的所有迭代都是独立的，或者确切地定义应该如何将循环调度为并行资源)。

并行循环的含义有些含糊不清——因为不同的并行编程语言会重载这个术语——但是许多常见的并行循环构造表示，编译器转换顺序循环。这样的编程模型使我们能够编写顺序循环，并且只需要提供有关如何安全地并行执行不同迭代的信息。这些模型非常强大，与其他编译器优化集成得很好，并且极大地简化了并行编程，但这不代表鼓励开发者在开发的早期阶段考虑并行性。

并行内核不是循环，也没有迭代。相反，内核表示一个操作，可以多次实例化，并应用于不同的输入数据；当内核并行启动时，该操作的多个实例将同时执行。

\hspace*{\fill}  %插入空行
图4-3 将循环重写(伪代码)为并行内核代码
\begin{lstlisting}[caption={}]
launch N kernel instances {
	int id = get_instance_id(); // unique identifier in [0, N)
	c[id] = a[id] + b[id];
}
\end{lstlisting}

图4-3展示了使用伪代码重写为内核的简单循环示例。这个内核中实现并行性是明确的:内核可以由任意数量的实例并行执行，每个实例独立地应用于单独的数据块。通过将此操作编写为内核，可以确定并行运行是安全的(理想情况下应该如此)。

简而言之，基于内核的编程不是一种使用并行改进顺序代码的方法，而是一种编写显式并行程序的方法。

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
我们越早将思路从并行循环转向内核，就越容易使用Data Parallel C++编写高效的并行程序。
\end{tcolorbox}

## 4.2 语言的特性

决定编写并行内核时，就必须要启动的内核类型，以及了解如何在程序中表示。并行内核很多种，如果想掌握，就要熟悉每一种方法。

\hspace*{\fill}  %插入空行
\textbf{将内核与主机代码分离}

有几种分离主机和设备代码的替代方法:C++ Lambda表达式或函数对象(functors)、OpenCL C源字符串或二进制文件。其中一些在第2章中已经介绍了，这些方式将在第10章中进行更详细地介绍。

这些选项都展示并行性的基本概念。为了一致性和简洁性，本章中的所有代码示例都使用C++ Lambda来表示内核。

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=Lambda无害于性能]
为了使用DPC++，不需要完全理解C++规范中关于Lambda的所有内容——只需要知道Lambda可以表示内核，并且可以捕获的变量(按值)作为参数传递给内核。

使用Lambda来定义内核不会产生性能影响。DPC++编译器能够理解Lambda表示并行内核的主体，并能够进行优化执行。

关于C++ Lambda函数的复习，以及它们在SYCL中的使用说明，请参见第1章。有关使用Lambda定义内核的详细信息，请参见第10章。
\end{tcolorbox}

\hspace*{\fill}  %插入空行
\textbf{不同形式的并行内核}

内核有三种不同的形式，支持不同的执行模型和语法。可以使用任何形式编写可移植的内核，并且可以对任何形式的内核进行调优，以在各种设备类型上实现高性能。然而，有时可能希望使用特定的形式使并行算法更容易表达，或者使用某些语言特性。

第一种形式用于基本的数据并行内核，为编写内核提供了最优雅的介绍。牺牲对底层特性的控制，使内核的表达式尽可能简单。单个内核实例如何映射到硬件资源完全由实现控制，因此随着内核的复杂性的增长，对其性能的控制会变得越来越困难。

第二种形式扩展了内核，以提供对底层性能调优的访问。由于历史原因，第二种形式称为ND-Range(N维范围)数据并行方式，其将某些内核实例分组在一起，允许对数据局域性的使用，以及内核实例和硬件资源之间的映射进行控制。

第三种形式提供了另一种语法，可以使用嵌套的内核构造来ND-Range内核。第三种形式称为分层数据并行，指的是嵌套内核的层次结构。

我们将在本章的最后再次讨论如何在不同的内核形式之间进行选择，届时将详细讨论了它们的特性。


## 4.3 内核间的数据并行

并行内核最基本的形式适用于基本的并行操作(例如：可以完全独立地、以任何顺序应用于每一块数据的操作)。通过使用这个形式，可以实现对调度的控制。因此，其是一个描述性编程结构的例子——调度决策由实现做出。

基本的数据并行内核是用单程序多数据(Single Program, Multiple Data, SPMD)风格编写的——“程序”(内核)应用于多段数据。注意，由于依赖于数据的分支，这个编程模型仍然允许内核在代码中采取不同的方式书写。

SPMD编程模型的最大优点，允许同一个“程序”映射到多个级别和类型的并行性，而无需提供任何指示。同一个程序的实例可以流水线化、打包在一起并使用SIMD指令执行、跨多个线程分布，或者混合使用这三种方法。

\hspace*{\fill}  %插入空行
\textbf{理解数据并行内核}

并行内核的执行空间称为执行范围，内核的每个实例称为工作项。如图4-4所示。

\hspace*{\fill}  %插入空行
图4-4 并行内核的执行空间，显示为2D范围内的64项
\begin{center}
	\includegraphics[width=0.6\textwidth]{content/chapter-4/images/3}
\end{center}

数据并行内核的执行模型非常简单:允许完全并行执行。工作项可以以任何顺序执行，包括在单个硬件线程上顺序执行(即，没有任何并行性)!假设所有工作项都并行执行的内核(例如，尝试同步工作项)，则很容易导致程序挂起。

为了保证正确性，必须假定内核可以并行执行。例如，确保对内存的并发访问可被原子操作保护(见第19章)，以避免条件竞争。

\hspace*{\fill}  %插入空行
\textbf{编写数据并行内核}

数据并行内核使用parallel\_for函数表示。图4-5展示了如何使用这个函数来表示向量加法。

\hspace*{\fill}  %插入空行
图4-5 使用parallel\_for表示向量加法的内核代码
\begin{lstlisting}[caption={}]
h.parallel_for(range{N}, [=](id<1> idx) {
	c[idx] = a[idx] + b[idx];
});
\end{lstlisting}

该函数只接受两个参数:第一个参数是一个范围，指定在每个维度中启动工作项的数量，第二个参数是执行的内核函数。可以接受几个不同的类作为内核函数的参数，应该使用哪个类取决于该类公开所需的功能—稍后我们将继续讨论这个问题。

图4-6展示了一个非常类似的使用该函数来表示矩阵加法，(数学上)与向量加法相同，只是这次用于二维数据。这反映在内核中——两个代码片段之间的唯一区别是使用的范围和id类的维度!可以这样编码，因为SYCL访问器可以通过多维id进行索引。虽然看起来很奇怪，但非常强大，使我们能够编写基于数据维度的模板内核。

\hspace*{\fill}  %插入空行
图4-6 用parallel\_for表示矩阵加法的内核代码
\begin{lstlisting}[caption={}]
h.parallel_for(range{N, M}, [=](id<2> idx) {
	c[idx] = a[idx] + b[idx];
});
\end{lstlisting}

C/C++中，使用多个索引和多个下标操作符为多维数据结构索引更为常见，访问器也支持这种显式索引。当内核同时操作不同维度的数据时，或者当内核的内存访问模式比直接使用项id描述的更复杂时，这种方式可以提高代码的可读性。

例如，图4-7中的矩阵乘法核必须提取索引的两个单独的分量，以便能够描述两个矩阵的行和列之间的点积。使用多个下标操作符(例如：[j][k])比混合多个索引模式和构造二维id对象(例如，id(j,k))更具可读性。

本章剩下的示例都使用了多个下标操作符，以确保访问的维度没有歧义。

\hspace*{\fill}  %插入空行
图4-7 用parallel\_for表示方阵矩阵乘法的内核代码
\begin{lstlisting}[caption={}]
h.parallel_for(range{N, N}, [=](id<2> idx) {
	int j = idx[0];
	int i = idx[1];
	for (int k = 0; k < N; ++k) {
		c[j][i] += a[j][k] * b[k][i];
		// c[idx] += a[id(j,k) * b[id(k,i)]; <<< equivalent
	}
});
\end{lstlisting}

\hspace*{\fill}  %插入空行
图4-8 将矩阵乘法映射到执行范围中的工作项上
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-4/images/4}
\end{center}

图4-8中展示了如何将矩阵乘法内核中的工作映射到各个项。注意工作项的数量是来自输出范围的大小，多个工作项可能使用同样的输入值：每一个工作项计算C矩阵的一个值，通过顺序迭代A矩阵的行(连续的)和B(不连续)矩阵的列完成。

\hspace*{\fill}  %插入空行
\textbf{数据并行内核的细节}

数据并行内核是通过三个C++类表示:range、id和item。前面的章节中，已经多次看到了range和id类，这里将以不同的重点继续讨论。

\hspace*{\fill}  %插入空行
\textbf{range类}

range表示1、2或3维范围。range的维度是一个模板参数，必须在编译时已知，但每个维度的大小是动态的，并在运行时传递给构造函数。range类的实例用于描述并行执行范围和缓冲区的大小。

range类的简化定义显示了查询长度，构造函数和其他各种方法，如图4-9所示。

\hspace*{\fill}  %插入空行
图4-9 简化的range类定义
\begin{lstlisting}[caption={}]
template <int Dimensions = 1>
class range {
public:
	// Construct a range with one, two or three dimensions
	range(size_t dim0);
	range(size_t dim0, size_t dim1);
	range(size_t dim0, size_t dim1, size_t dim2);
	
	// Return the size of the range in a specific dimension 
	size_t get(int dimension) const;
	size_t &operator[](int dimension);
	size_t operator[](int dimension) const;
	
	// Return the product of the size of each dimension
	size_t size() const;
	
	// Arithmetic operations on ranges are also supported
};
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{id类}

id表示1、2或3维范围的索引。id的定义在许多方面与range相似:维数也必须在编译时已知，并且可以用于在索引内核的单个实例，或在缓冲区中创建偏移。

如图4-10中id类的简化定义所示，id在概念上只是包含1、2或3个整数的容器。可用的操作也非常简单:可以查询每个维度中索引，计算新的索引。

尽管可以构造id来表示任意索引，但要获得与特定内核实例关联的id，必须将它(或包含它的项)作为内核函数的参数。这个id(或它的成员函数返回的值)必须转发到任何想要查询索引的函数中——目前没有任何可以在程序中任意点查询索引的函数，但是这个问题DPC++会在未来来解决。

每个接受id的内核实例只知道分配给它计算的范围内的索引，而对range一无所知。如果想让内核实例知道自己的索引和范围，需要使用item类。

\hspace*{\fill}  %插入空行
图4-10 简化的id类定义
\begin{lstlisting}[caption={}]
template <int Dimensions = 1>
class id {
public:
	// Construct an id with one, two or three dimensions
	id(size_t dim0);
	id(size_t dim0, size_t dim1);
	id(size_t dim0, size_t dim1, size_t dim2);
	
	// Return the component of the id in a specific dimension 
	size_t get(int dimension) const;
	size_t &operator[](int dimension);
	size_t operator[](int dimension) const;
	
	// Arithmetic operations on ids are also supported
};
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{item类}

item表示内核函数的单个实例，封装了内核的执行range和实例在该range内的索引(分别使用一个range和一个id)。与range和id一样，维度必须在编译时就已知。

图4-11给出了工作项类的简化定义。item和id之间的主要区别是，item公开了额外的函数来查询执行范围的属性(例如：大小、偏移量)和一个计算线性化索引的函数。与id一样，获得与特定内核实例相关联的项的唯一方法是将它作为内核函数的参数。

\hspace*{\fill}  %插入空行
图4-11 简化的item类定义
\begin{lstlisting}[caption={}]
template <int Dimensions = 1, bool WithOffset = true>
class item {
public:
	// Return the index of this item in the kernel's execution range
	id<Dimensions> get_id() const;
	size_t get_id(int dimension) const;
	size_t operator[](int dimension) const;
	
	// Return the execution range of the kernel executed by this item
	range<Dimensions> get_range() const;
	size_t get_range(int dimension) const;
	
	// Return the offset of this item (if with_offset == true)
	id<Dimensions> get_offset() const;
	
	// Return the linear index of this item
	// e.g. id(0) * range(1) * range(2) + id(1) * range(2) + id(2)
	size_t get_linear_id() const;
};
\end{lstlisting}


## 4.4 显式ND-Range内核

并行内核的第二种形式是在执行范围内执行，其中工作项属于工作组，符合内核中局域性的概念。不同类型的工作组定义和行为不同，并且可以了解和/或控制将工作映射到特定的硬件平台。

显式的ND-Range内核是并行的——对每种工作组的工作进行映射，并且必须遵守这种映射。但这并不是完全定死的，因为工作组本身可以按任何顺序执行，并且实现将每种类型工作组映射到硬件资源上，并保留一定的自由度。这种说明性和描述性编程的结合能进行局部性设计和调优内核，且不会影响可移植性。

与数据并行内核一样，ND-Range内核以SPMD风格编写，所有工作项执行应用于多个数据块的相同内核。区别是，每个程序实例可以查询在工作组中的位置，并可以访问特定于每种类型组的其他功能。

\hspace*{\fill}  %插入空行
\textbf{理解ND-Range并行内核}

ND-Range内核的执行范围可以划分为工作组、子工作组和工作项。ND-Range表示总的执行范围，将其划分为统一大小的工作组(即工作组大小必须在每个维度上精确划分ND-Range大小)。每个工作组可以通过实现进一步划分为子工作组。工作项和每种组的执行模型是编写正确和可移植程序的重要部分。

图4-12展示了将(8,8,8)的ND-Range划分为8个大小(4,4,4)的工作组。每个工作组包含由4个工作项组成的16个一维子工作组。注意维度的编号:子工作组是一维的，因此ND-Range和工作组的维度2，变成子组的维度0。

\hspace*{\fill}  %插入空行
图4-12 3维ND-Range划分为工作组、子工作组和工作项
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-4/images/5}
\end{center}

每种组到硬件资源的映射由实现定义，这种灵活性使程序能够在各种硬件上执行。例如，工作项可以完全顺序执行，可以由硬件线程和/或SIMD指令并行执行，甚至可以由特定的硬件执行。

本章中，我们只关注在通用平台上ND-Range的执行模型，并且不讨论对任何平台的映射。关于GPU、CPU和FPGA的硬件映射和性能建议，分别在第15、16和17章进行介绍。

\hspace*{\fill}  %插入空行
\textbf{工作项}

工作项表示内核函数的各个实例。没有其他分组的情况下，工作项可以以任何顺序执行，除非通过对全局内存的原子操作(参见第19章)，否则不能相互通信或同步。

\hspace*{\fill}  %插入空行
\textbf{工作组}

ND-Range中的工作项可以组成工作组。工作组可以以任何顺序执行，并且不同工作组中的工作项不能相互通信，除非通过对全局内存的原子内存操作(参见第19章)。然而，使用某些构造时，工作组中的工作项可并发调度，并且这种局部性提供的能力有:

\begin{enumerate}
	\item 工作组中的工作项可以访问工作组本地内存，这些内存可以映射到某些设备上的专用快速内存(参见第9章)。
	\item 工作组中的工作项可以使用工作组栅栏进行同步，并使用工作组内存栅栏保证内存一致性(参见第9章)。
	\item 工作组中的工作项可以访问组函数，提供可通信例程的实现(见第9章)和常规并行模式(归约和扫描)(见第14章)。
\end{enumerate}

工作组的工作项数量通常在运行时为内核配置，最佳分组将取决于可用的并行度(即ND-Range的大小)和目标设备的属性。我们可以使用设备类的查询函数，来确定特定设备支持的每个工作组的最大工作项数量(见第12章)，我们的责任是确保每个内核请求的工作组大小有效。

首先，工作组中的工作项可以调度单个计算单元，但工作组的数量和计算单元的数量之间不需要有任何关系。ND-Range内的工作组数量可能比给定设备可并发执行的工作组数量大很多倍！我们依靠特定于设备的调度，尝试和编写内核同步工作组，但不建议这样做，因为不能保证与实现可能会在与之前不同的设备上运行。

其次，工作组中的工作项可以同时进行工作，但不能保证工作的独立性时——在工作组中使用栅栏和集合，可以对组内工作项进行同步。同一个工作组中工作项之间的通信和同步，只有在使用栅栏和集合操作时才能保证安全，手工编码的同步可能会造成死锁。

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=对于工作组的思考]
工作组在许多方面与其他编程模型中的任务概念相似(例如：线程块):任务可以按任何顺序执行(由调度程序控制)；开辟大量的任务是可能的(甚至是可取的)；在一组任务之间使用栅栏，通常不是个好主意(因为它可能非常昂贵或与调度器不兼容)。如果已经熟悉了基于任务的编程模型，会发现将工作组看作是数据并行的任务就会更好理解。
\end{tcolorbox}

\hspace*{\fill}  %插入空行
\textbf{子工作组}

许多硬件平台上，工作组中的子工作组在执行时具有调度上的保证。例如，子工作组中的工作项可以同时执行，因为可以映射到独立的硬件线程，子工作组本身可以在保证内核进度的情况下执行。

使用单一平台时，很容易在代码中加入执行模型的假设，但这使得内核不安全、不可移植——当在不同的编译器之间使用时，有时来自同一厂商的不同一代硬件之间迁移时，都可能会崩溃!

将子工作组为语言的核心部分，利用子工作组我们可以在底层硬件上执行工作项，并且还可以为跨平台实现高性能级别的应用。

与工作组一样，子工作组中的工作项可以同步、保证内存一致性，或通过工作组功能执行常见的并行模式。但对于子工作组没有等价的工作组本地内存(没有子组本地内存)。相反，子工作组中的工作项可以直接交换数据——无需显式的内存操作——使用shuffle操作(第9章)。

子工作组的某些功能由实现定义，不在我们的控制范围内。对于给定的设备、内核和ND-Range组合，子工作组具有固定的(一维的)大小，可以使用内核类的查询函数来查询(见第10章)。默认情况下，每个子工作组的工作项数量也由实现选择——可以通过在编译时请求特定的子组大小来覆盖这个行为，但是必须确保子工作组大小与设备兼容。

与工作组类似，子工作组中的工作项只保证并行执行——实现可以自由地顺序执行每个工作项，并且只有在遇到集合函数时才会在工作项之间切换。子工作组的特殊之处在于，某些设备保证独立地执行——工作组中的所有子工作组都保证可以执行(取得进展)，这是若干生产者-消费者模式的基础。这个独立的执行是否能保持，可以通过查询设备来确定。

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=对于子工作组的思考]
如果考虑显式向量化的编程模型，那么将每个子工作组看作打包到SIMD寄存器中的一组工作项可能会更容易理解，其中子工作组中的每个工作项对应于一个SIMD通道。当多个子工作组同时执行时，硬件设备可以保证任务的执行，这种模型扩展会把每个子工作组当作并行执行的独立向量指令流。
\end{tcolorbox}

\hspace*{\fill}  %插入空行
图4-13 用ND-Range parallel\_for表示矩阵乘法
\begin{lstlisting}[caption={}]
range global{N, N};
range local{B, B};
h.parallel_for(nd_range{global, local}, [=](nd_item<2> it) {
	int j = it.get_global_id(0);
	int i = it.get_global_id(1);
	
	for (int k = 0; k < N; ++k)
		c[j][i] += a[j][k] * b[k][i];
});
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{编写ND-Range数据并行内核}

图4-13重新实现了使用ND-Range parallel\_for内核编写的矩阵乘法内核，图4-14中展示了这个内核是如何映射到每个工作项中的。以这种方式对工作项进行分组，从而保证本地的访问高效性，提高缓存命中率:例如，工作组在图4-14的大小是(4，4)，包含16个工作项，为了每个工作项都能执行正常，相应的数据需要加载4次。

\hspace*{\fill}  %插入空行
图4-14 将矩阵乘法映射到工作组和工作项
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-4/images/8}
\end{center}

目前为止，矩阵乘法示例依赖于硬件缓存对同一个工作组中工作项A和B矩阵的重复访问进行优化。这样的硬件缓存在传统的CPU架构中很常见，而且在GPU架构中也越来越常见，但是也有其他架构(如上一代GPU、FPGA)带有“暂存”内存。ND-Range内核可以使用本地访问器来说明工作组的本地内存分配的位置，然后实现就可以自由地将这些分配映射到特定内存(它存在的地方)。工作组本地内存的使用将在第9章中介绍。

\hspace*{\fill}  %插入空行
\textbf{ND-Range数据并行内核的细节}

与数据并行内核相比，ND-Range内核可以使用不同的类:nd\_range替换range，nd\_item替换item。还有两个新类，表示工作项属于的不同类型的组:绑定工作组的功能封装在group类中，绑定到子工作组的功能封装在sub\_group类中。

\hspace*{\fill}  %插入空行
\textbf{nd\_range类}

nd\_range表示使用range类的两个实例组成的执行范围:一个表示全局执行范围，另一个表示每个工作组的本地执行范围。图4-15给出了nd\_range类的简化定义。

nd\_range类根本没有提到子工作组：子工作组范围在构造期间没有指定，不能查询。这有两个原因，1.子工作组是可以忽略的底层实现细节。2.有设备只支持固定的的子工作组大小，从而指定大小没有必要。所有与子工作组相关的功能都封装在特定的类中，稍后将对此再进行讨论。

\hspace*{\fill}  %插入空行
图4-15 简化定义的nd\_range类
\begin{lstlisting}[caption={}]
template <int Dimensions = 1>
class nd_range {
public:
	// Construct an nd_range from global and work-group local ranges
	nd_range(range<Dimensions> global, range<Dimensions> local);
	
	// Return the global and work-group local ranges
	range<Dimensions> get_global_range() const;
	range<Dimensions> get_local_range() const;
	
	// Return the number of work-groups in the global range
	range<Dimensions> get_group_range() const;
};
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{nd\_item类}

nd\_item是工作项的ND-Range形式，封装了内核的执行范围和工作项的索引。nd\_item与item的区别在于范围中的位置查询和表示，如图4-16中简化的类定义所示。

例如，可以使用get\_global\_id()函数在(全局)ND-Range中查询工作项的索引，或者使用get\_local\_id()函数在(本地)父工作组中查询工作项的索引。

nd\_item类还提供了获取描述项所属的工作组和子工作组的类句柄的函数。这些类为查询DN-Range的工作项索引提供了另一种方式。我们强烈推荐使用这些类来编写内核，而不是依赖于nd\_item，使用group和sub\_group类通常更简洁，更清晰，也更符合DPC++的方向。

\hspace*{\fill}  %插入空行
图4-16 简化定义的nd\_item类
\begin{lstlisting}[caption={}]
template <int Dimensions = 1>
class nd_item {
public:
	// Return the index of this item in the kernel's execution range
	id<Dimensions> get_global_id() const;
	size_t get_global_id(int dimension) const;
	size_t get_global_linear_id() const;
	
	// Return the execution range of the kernel executed by this item
	range<Dimensions> get_global_range() const;
	size_t get_global_range(int dimension) const;
	
	// Return the index of this item within its parent work-group
	id<Dimensions> get_local_id() const;
	size_t get_local_id(int dimension) const;
	size_t get_local_linear_id() const;
	
	// Return the execution range of this item's parent work-group
	range<Dimensions> get_local_range() const;
	size_t get_local_range(int dimension) const;
	
	// Return a handle to the work-group
	// or sub-group containing this item
	group<Dimensions> get_group() const;
	sub_group get_sub_group() const;
};
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{group类}

group类封装了与工作组相关的所有功能，简化的定义如图4-17所示。

\hspace*{\fill}  %插入空行
图4-17 简化定义的group类
\begin{lstlisting}[caption={}]
template <int Dimensions = 1>
class group {
public:
	// Return the index of this group in the kernel's execution range
	id<Dimensions> get_id() const;
	size_t get_id(int dimension) const;
	size_t get_linear_id() const;
	
	// Return the number of groups in the kernel's execution range
	range<Dimensions> get_group_range() const;
	size_t get_group_range(int dimension) const;
	
	// Return the number of work-items in this group
	range<Dimensions> get_local_range() const;
	size_t get_local_range(int dimension) const;
};
\end{lstlisting}

group类提供的许多函数在nd\_item类中都有对等的函数:例如，group.get\_id()等价于item.get\_group\_id()，group.Get \_local\_range()等价于item.get\_local\_range()。如果不使用该类的任何工作组函数，还应该使用它吗?直接使用nd\_item中的函数，不是更简单吗?这里有一个折衷的方式:使用group要求编写更多的代码，但这些代码可能更容易阅读。例如，图4-18中的代码片段:body由工作组中的所有工作项调用，parallel\_for的中的get\_local\_range()返回的范围就是工作组的范围。只用nd\_item就可以很容易地编写相同的代码，但代码可能很难看懂。

\hspace*{\fill}  %插入空行
图4-18 使用group类来提高可读性
\begin{lstlisting}[caption={}]
void body(group& g);
h.parallel_for(nd_range{global, local}, [=](nd_item<1> it) {
	group<1> g = it.get_group();
	range<1> r = g.get_local_range();
	...
	body(g);
});
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{sub\_group类}

sub\_group类封装了与子工作组相关的功能，简化的定义如图4-19所示。与工作组不同，sub\_group类是访问子工作组功能的唯一方法，其函数在nd\_item中没有重复。sub\_group类中的查询都是相对于工作项进行解释的:例如，get\_local\_id()返回子工作组中调用工作项的本地索引。

\hspace*{\fill}  %插入空行
图4-19 简化定义的sub\_group类
\begin{lstlisting}[caption={}]
class sub_group {
	public:
	// Return the index of the sub-group
	id<1> get_group_id() const;
	
	// Return the number of sub-groups in this item's parent work-group
	range<1> get_group_range() const;
	
	// Return the index of the work-item in this sub-group
	id<1> get_local_id() const;
	
	// Return the number of work-items in this sub-group
	range<1> get_local_range() const;
	
	// Return the maximum number of work-items in any 
	// sub-group in this item's parent work-group
	range<1> get_max_local_range() const;
};
\end{lstlisting}

有一些功能用于查询当前子工作组中的工作项数量，以及工作组中任何子工作组中的最大工作项数量。这些方式取决于设备对于子工作组的实现的方式，但其目的是反映编译器目标子工作组大小和运行时子工作组大小之间的差异。例如，非常小的工作组可能包含比编译时子工作组更少的工作项，或者不同大小的子工作组可能用于处理不能被子组大小整除的工作组。



## 4.5 内核间的分层并行

分层数据并行内核提供了实验性的替代语法，可以用工作组和工作项来表示内核，其中层次结构的每一层都使用parallel\_for嵌套调用。这种自顶向下的编程风格类似于编写并行循环，可能比其他两种内核形式使用的自底向上编程风格更为开发者和读者熟悉。

分层内核的复杂性在于，paralle\_for的嵌套调用会创建单独的SPMD环境，每个范围定义了新的“程序”，其应由与该范围相关的并行工作项执行。这种复杂性要求编译器进行分析，并可能使生成某些设备的代码复杂化。一些平台上用于分层并行内核的编译器技术仍然不成熟，性能与编译器实现的质量密切相关。

由于分层数据并行内核和为特定设备生成的代码之间的关系依赖于编译器，因此分层内核应该比显式的ND-Range内核更具描述性的结构。由于分层内核保留了控制任务映射工作项和工作组的能力，因此比基本内核更具有特定性。

\hspace*{\fill}  %插入空行
\textbf{理解分层的数据并行内核}

分层数据并行内核的底层执行模型，与显式ND-Range数据并行内核的执行模型相同。工作项、子工作组和工作组具有相同的语义和执行保证。

然而，分层内核的不同作用域由编译器映射到不同的执行资源:外部作用域对每个工作组执行一次(就像由单个工作项执行一样)，而内部作用域由工作组中的工作项并行执行。不同的作用域还控制内存中分配变量的位置，并且作用域的打开和关闭意味着启用工作组栅栏(以强制执行内存一致性)。

尽管工作组中的工作项仍然划分为子工作组，但不能在分层并行内核访问sub\_group类，将子工作组的概念合并到SYCL分层并行中，是比引入新类更重要的修改，这个工作正在进行中。

\hspace*{\fill}  %插入空行
\textbf{编写分层的数据并行内核}

分层内核中，parallel\_for\_work\_group和parallel\_for\_work\_item可以取代parallel\_for，分别对应于工作组和工作项的并行性。parallel\_for\_work\_group作用域中的任何代码在工作组中只执行一次，并且在parallel\_for\_work\_group作用域中分配的变量对所有工作项都可见(在工作组本地内存中分配)。在parallel\_for\_work\_item范围内的任何代码，都是由工作组的工作项目并行执行，并且在parallel\_for\_work\_item范围内分配的变量对单个工作项都可见(可以分配在工作项的私有内存中)。

如图4-20所示，分层并行表示的内核与ND-Range内核非常相似。因此，应该把分层并行看作是一种生产力象征，不公开任何未通过ND-Range内核公开的功能，但可以提高代码的可读性和/或减少代码量。

\hspace*{\fill}  %插入空行
图4-20 表示具有层次并行性的矩阵乘法
\begin{lstlisting}[caption={}]
range num_groups{N / B, N / B}; // N is a multiple of B
range group_size{B, B};
h.parallel_for_work_group(num_groups, group_size, [=](group<2> grp) {
	int jb = grp.get_id(0);
	int ib = grp.get_id(1);
	grp.parallel_for_work_item([&](h_item<2> it) {
		int j = jb * B + it.get_local_id(0);
		int i = ib * B + it.get_local_id(1);
		for (int k = 0; k < N; ++k)
		c[j][i] += a[j][k] * b[k][i];
	});
});
\end{lstlisting}

需要注意的是，传递给parallel\_for\_work\_group的范围指定了组的数量和可选组的大小，而不是像ND-Range parallel\_for那样指定了工作项的总数和工作组大小。内核函数可传入组类的实例，反映出范围与工作组的关系，而不与单个工作项相关系。

parallel\_for\_work\_item是group类的一个成员函数，只能在parallel\_for\_work\_group的作用域内调用。在其最简形式中，唯一的参数是接受h\_item类实例的函数，该函数可以执行的次数等于每个工作组请求的工作项的数量。parallel\_for\_work\_item的另一个特性是支持逻辑范围的能力，作为附加参数传递给函数。当指定一个逻辑范围时，每个物理工作项执行零个或多个函数实例，并且逻辑范围的逻辑项会轮询，并分配给物理工作项。

图4-21显示了由11个逻辑工作项组成的逻辑范围，和由8个物理工作项组成的底层物理范围间的映射示例。前三个工作项分配了功能的两个实例，而其他工作项只分配了一个。

\hspace*{\fill}  %插入空行
图4-21 将大小为11的逻辑范围映射为大小为8的物理范围
\begin{center}
	\includegraphics[width=1.\textwidth]{content/chapter-4/images/6}
\end{center}

如图4-22所示，将parallel\_for\_work\_group的可选组与parallel\_for\_work\_item的逻辑范围相结合，可以自由选择工作组大小，方便描述执行范围的能力。请注意，每个组执行的工作量与图4-20中相同，但是工作量已经与物理工作组大小不同了。

\hspace*{\fill}  %插入空行
图4-22 用层次并行性和逻辑范围表示矩阵乘法
\begin{lstlisting}[caption={}]
range num_groups{N / B, N / B}; // N is a multiple of B
range group_size{B, B};
h.parallel_for_work_group(num_groups, [=](group<2> grp) {
	int jb = grp.get_id(0);
	int ib = grp.get_id(1);
	grp.parallel_for_work_item(group_size, [&](h_item<2> it) {
		int j = jb * B + it.get_logical_local_id(0);
		int i = ib * B + it.get_logical_local_id(1);
		for (int k = 0; k < N; ++k)
		c[j][i] += a[j][k] * b[k][i];
	});
});
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{分层数据并行内核的细节}

分层数据并行内核重用来自ND-Range数据并行内核的group类，但需要将nd\_item替换为h\_item。引入新的私有内存类，以便在parallel\_for\_work\_group范围内对分配进行更严格的控制。

\hspace*{\fill}  %插入空行
\textbf{h\_item类}

h\_item是item的变体，只能在parallel\_for\_work\_item作用域内使用。如图4-23，提供了一个类似的接口nd\_item:可以查询工作项的的工作组(get\_physical\_local\_id())或逻辑执行范围parallel\_for\_work\_item(使用get\_logical\_local\_id())。

\hspace*{\fill}  %插入空行
图4-23 简化定义的h\_item类
\begin{lstlisting}[caption={}]
template <int Dimensions>
class h_item {
	public:
	// Return item's index in the kernel's execution range
	id<Dimensions> get_global_id() const;
	range<Dimensions> get_global_range() const;
	
	// Return the index in the work-group's execution range
	id<Dimensions> get_logical_local_id() const;
	range<Dimensions> get_logical_local_range() const;
	
	// Return the index in the logical execution range of the parallel_for
	id<Dimensions> get_physical_local_id() const;
	range<Dimensions> get_physical_local_range() const;
};
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{private\_memory类}

private\_memory类提供了一种机制来声明每个工作项的私有变量，嵌套在同一个parallel\_for\_work\_group作用域内的多个parallel\_for\_work\_item都可以访问这些变量。

这个类非常必要，因为不同的分层并行性范围中的变量声明不同:如果编译器能够保证安全，则变量声明是私有的。我们不可能单独使用作用域，来表达变量是工作项私有的。

要了解为什么这是一个问题，回顾一下图4-22中的矩阵乘法内核。ib和jb变量是在parallel\_for\_work\_group作用域声明的，默认情况下应该在工作组的本地内存中分配!编译器很有可能不会犯这个错误，因为变量是只读的，可以在每个工作项上进行冗余计算，但语言并没有这样的保证。如果想确定一个变量是否在工作项私有内存中，需要将变量声明包装在private\_memory类的实例中，如图4-24所示。

\hspace*{\fill}  %插入空行
图4-24 简化定义的private\_memory类
\begin{lstlisting}[caption={}]
template <typename T, int Dimensions = 1>
class private_memory {
	public:
	// Construct a private variable for each work-item in the group
	private_memory(const group<Dimensions>&);
	
	// Return the private variable associated with this work-item
	T& operator(const h_item<Dimensions>&);
};
\end{lstlisting}

例如，如果使用private\_memory类重写矩阵乘法内核，把变量定义为private\_memory<int> ib(grp)，并且对这些变量的访问变成ib[item]。这样，使用private\_memory类的代码非常难读，而在parallel\_for\_work\_item范围中声明则会更简单。

如果工作项私有变量在多个parallel\_for\_work\_item范围内，并且在同一parallel\_for\_work\_group上使用，建议只使用private\_memory类，可以避免多余地计算。要不就依赖现代优化编译器的能力，并且只有在变量分析失败时才在parallel\_for\_work\_item范围声明变量(记住，也要向编译器供应商报告问题)。



## 4.6 将计算映射到工作项中

目前为止，大多数代码示例都假设内核函数的每个实例对应于单个数据块上的单个操作。这是编写内核的一个简单方法，但这种数据与工作项的一一映射不是由DPC++全控制的，所以使得任务参数化是提高应用性能和可移植性的好方法。

\hspace*{\fill}  %插入空行
\textbf{一对一映射}

当编写与工作项的一一映射的内核时，这些内核需要完成的工作量必须适配range或nd\_range的大小。这是编写内核的最简单的方式，这种方式工作得非常好——可以信底层任实现工作项映射到硬件。

然而，对系统和实现的特定组合进行性能调优时，需要更加注意底层调度。工作组对计算资源的调度由实现定义，并且可能是动态的(例如，当一个计算资源完成一个工作组时，执行的下一个工作组可能来自于共享队列)。动态调度对性能的影响不确定，其重要性取决于内核函数每个实例的执行时间，以及调度软件(如CPU)或硬件(如GPU)上的实现。

\hspace*{\fill}  %插入空行
\textbf{多对一映射}

另一种方法是编写多对一映射的内核，range的含义略有变化:不再描述要完成的工作量，而是要使用的工作项的数量。通过改变工作项的数量和分配给每个工作项的工作量，可以调整工作分配，以最大限度地提高效率。

编写这种形式的内核需要做两个更改:

\begin{itemize}
	\item 内核必须接受描述工作总量的参数。
	\item 内核必须包含将工作分配给工作项的循环。
\end{itemize}

图4-25给出了这样的内核示例，内部的循环稍微不同寻常——起始索引是全局范围内工作项的索引，而跨距是工作项的总数。这种数据到工作项的循环调度确保了循环的所有N次迭代将由一个工作项执行，而且线性工作项可以访问连续的内存位置(以改进缓存局部性和向量化行为)。工作可以分布在多个工作组或单个工作组中的工作项中，以进一步利用局部性。

\hspace*{\fill}  %插入空行
图4-25 具有独立数据和执行范围的内核
\begin{lstlisting}[caption={}]
size_t N = ...; // amount of work
size_t W = ...; // number of workers
h.parallel_for(range{W}, [=](item<1> it) {
	for (int i = it.get_id()[0]; i < N; i += it.get_range()[0]) {
		output[i] = function(input[i]);
	}
});
\end{lstlisting}

这些分发模式很常见，使用具有逻辑范围的分层并行时，可以使用。我们期望未来的DPC++引入语法糖，来简化ND-Range内核中分发模式的表示。


## 4.7 选择内核形式
在不同的内核形式之间进行选择，很大程度上取决于个人偏好，并且很受到以前使用其他并行编程模型和语言经验的影响。

选择内核形式的另一个原因是，公开内核所需的功能。不幸的是，在开发开始之前很难确定需要哪些功能——特别是当我们不熟悉不同的内核形式，以及它们与各种类是如何交互时。

为了帮助读者们进行选择，我们根据自己的经验构建了两个指南。读者可以参考这些经验法则，但最好的方法是选择不同的内核形式进行编写，对不同的方式进行测试和了解，从而在开发应用程序时选择最合适的内核形式和开发方式。

第一个指南是如图4-26所示的流程图：

\begin{itemize}
	\item 是否有并行编程的经验
	\item 是从头编写新代码，还是移植用现有的并行程序
	\item 是包含嵌套的并行，还是在内核函数的不同实例之间重用数据
	\item 用SYCL编写新内核是为了最大化性能，还是为了提高代码的可移植性，使用比底层的语言更高效的方式表示并行性
\end{itemize}

\hspace*{\fill}  %插入空行
图4-26 选择正确的内核形式
\begin{center}
	\includegraphics[width=0.8\textwidth]{content/chapter-4/images/7}
\end{center}

第二个指南是图4-27中的表格，总结了每种内核形式公开的功能。值得注意的是，这个表反映了DPC++在本书出版时的状态，随着语言的发展，每个内核形式可用的特性会发生变化。预计基本趋势将保持不变:基本的数据并行内核不会公开位置感知特性，显式的ND-Range内核会公开所有支持性能的特性，分层内核在公开特性方面会落后于显式的ND-Range内核，但是对这些特性的表达将使用更高层的抽象。

\hspace*{\fill}  %插入空行
图4-27 每种内核形式的特性
\begin{table}[H]
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{特性}                           & \multicolumn{1}{l|}{\textbf{基本内核}} & \multicolumn{1}{l|}{\textbf{ND-Range内核}} & \multicolumn{1}{l|}{\textbf{层次内核}} \\ \hline
		\textbf{工作组本地内存}           & No                                         & Yes                                           & Yes                                              \\ \hline
		\textbf{工作组栅栏}               & No                                         & Yes                                           & Yes                                              \\ \hline
		\textbf{子工作组}                        & No                                         & Yes                                           & No                                               \\ \hline
		\textbf{工作组函数(比如：scan,reduce)} & No                                         & Yes                                           & No                                               \\ \hline
	\end{tabular}
\end{table}



## 4.8 总结

本章介绍了在DPC++中表达并行性的基础知识，并讨论了编写数据并行内核的每种方法的优缺点。

DPC++和SYCL为许多形式的并行提供了支持，希望已经提供了足够的信息，以便读者准备开始编写代码!

我们只讨论了表面的内容，接下来将深入讨论本章中介绍的许多概念和类:本地内存、栅栏和通信的使用将在第9章中讨论；除了使用Lambda表达式外，定义内核的不同方法将在第10章继续；ND-Range执行模型到特定硬件的详细映射将在第15、16和17章中讨论；第14章将介绍使用DPC++并行模式的最佳实践。
