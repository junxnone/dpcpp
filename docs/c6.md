# 6 统一共享内存

\begin{center}
	\includegraphics[width=0.3\textwidth]{content/chapter-6/images/1}
\end{center}

接下来的两章将深入探讨如何管理数据。有两种方法:统一共享内存(USM)和缓冲区。USM的接口级别与缓冲区不同——USM是指针，而缓冲区使用更高级别的接口。本章主要介绍USM。

USM是一种基于指针的内存模型，可以通过指针读写内存。
## 6.1 为什么要使用统一共享内存

USM基于指针，对于基于指针的C++代码来说使用很自然，使用指针作为参数的已有函数不需要进行修改。大多数情况下，唯一需要更改的是使用USM的分配方式替换现有的malloc或new，我们将在本章中讨论这些分配方式。


## 6.2 分配类型
虽然USM基于指针，但不是所有指针都相同。USM定义了三种不同的分配类型，每种都有单独的方式。设备可能不支持所有类型的USM(甚至不支持)，后面我们会去了解到如何查询设备支持的USM类型。先来了解一下这三种类型的分配和特征，如图6-1所示。

\hspace*{\fill}  %插入空行
图6-1 USM分配方式
\begin{table}[H]
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		类型   & 描述                                & 主机端可访问? & 设备端可访问? & 位于                          \\ \hline
		device & 在设备内存上进行分配              & \XSolidBrush                   & \Checkmark                      & 设备                              \\ \hline
		host   & 在主机内存上进行分配                 & \Checkmark                   & \Checkmark                     & 主机端                                \\ \hline
		shared & 可在主机端和设备端共享 & \Checkmark                    & \Checkmark                     & 可以在主机和设备之间迁移 \\ \hline
	\end{tabular}
\end{table}

\hspace*{\fill}  %插入空行
\textbf{设备端内存}

这种类型的分配可以拥有指向设备内存(如(G)DDR或HBM)的指针。设备内存可以由运行在设备上的内核函数读取或写入，但是不能从主机直接访问。尝试直接访问设备端内存，可能导致数据不正确或程序崩溃。必须显式使用USM的memcpy机制在主机和设备之间复制数据，对两个位置上的数据进行复制，本章后面会对此继续讨论。

\hspace*{\fill}  %插入空行
\textbf{主机端内存}

第二种类型更容易使用，不需要在主机和设备之间复制数据。在主机和设备上都可以访问主机内存，虽然在设备上可以访问，但不能迁移到设备端内存。对该内存进行读写的内核通常通过较慢的总线(如PCI-Express)进行远程操作，所以必须对编程复杂性和性能进行权衡。尽管主机端的内存可能导致很高的访问成本，但也有使用的场景，比如：很少访问的数据或存在设备内存中无法容纳的大型数据集。

\hspace*{\fill}  %插入空行
\textbf{共享内存}

最后一种类型的内存分配结合了设备和主机内存的属性，结合了主机内存对编程复杂性的便利和设备分配提供的更好的性能，共享内存可以在主机和设备上访问。区别是共享内存可以自动地在主机内存和设备内存之间迁移，无需显式干预。如果数据已经迁移到该设备，那么在该设备上执行的内核访问该段数据，会比从主机远程访问该数据有更好的性能。不过，也有缺点。

自动迁移可以通过多种方式实现。不管运行时选择哪种方式来实现共享内存，通常都要付出延迟增加的代价。通过设备内存，可以确切地知道需要复制多少内存，并可以尽可能快地安排数据的复制。自动迁移机制无法对未来进行预见，某些情况下，直到内核尝试访问数据时才开始移动数据，导致内核必须等待或阻塞，直到数据移动完成。其他情况下，运行时很可能不知道内核函数将访问多少数据，可能移动更多的数据，这也会增加内核的延迟。

虽然共享分配可以迁移，但并不一定DPC++的所有实现都会迁移。我们希望大多数实现都通过迁移实现共享，但有些设备可能希望实现与主机内存相同。这样的实现中，分配的内存在主机和设备上仍然可见，但是可能无法感知迁移带来的性能提升。

## 6.3 分配内存

USM可以以各种不同的方式分配内存，以满足不同的需求。在更详细地讨论所有方法之前，应该了解一下USM分配与C++分配的区别。

\hspace*{\fill}  %插入空行
\textbf{需要知道什么?}

普通的C++程序可以以多种方式分配内存:new、malloc或分配器。不管使用哪种语法，内存分配最终都由主机操作系统中的系统分配器执行。当在C++中分配内存时，唯一需要考虑的是“需要多少内存?”和“可以分配多少内存?”但是，USM需要更多的信息才能进行分配。

首先，USM分配需要指定分配类型:device、host或shared。为了获得该分配所需的行为，使用正确的分配类型非常重要。每个USM必须指定一个上下文对象来进行分配，上下文表示可以在对应的设备上执行内核。可以把上下文看作是运行时存储设备状态的容器。大多数DPC++程序中，开发者可能不直接与上下文交互，而只是传递上下文。

不能保证USM分配可以跨不同的上下文使用——所有USM的分配、队列和内核共享同一个上下文对象。通常，可以从队列中获得上下文。设备分配还要求指定在哪个设备上分配内存，因为我们不想过度分配设备的内存(除非设备能够支持这一点——本章后续会对数据迁移时进行更多的讨论)。USM分配例程可以通过添加参数来区别于C++原生的方式。

\hspace*{\fill}  %插入空行
\textbf{多重样式}

想用单一的选项来取悦每个人是不可能的，就像有些人喜欢咖啡而不是茶，或者喜欢emacs而不是vi一样。USM支持选择的多样性，并提供了几种不同类型的分配接口：C风格、C++风格和C++分配器风格。将逐个讨论，并指出相同点和不同点。

\hspace*{\fill}  %插入空行
\textbf{C风格的分配方式}

第一种类型的分配函数(图6-2中列出，在随后的图6-6和6-7中中使用): malloc函数中的内存分配，函数需要返回一个void *指针(模仿C语言)。同时，必须指定要分配的总字节数，当要分配N个类型为X的对象，就必须要求总字节数为N * sizeof(X)。返回的指针为void *类型，必须将其转换为指向X类型的指针。这种方式非常简单，但由于需要进行大小计算和类型转换，因此会让代码看起来很冗长。

可以进一步将这种分配方式分为两类:命名函数和单函数。这两种方式的区别在于我们如何指定所需的USM分配类型。对于命名函数(malloc\_device、malloc\_host和malloc\_shared)，USM分配的类型编码在函数名中，单函数malloc要求将USM分配的类型指定为一个参数。具体要使用哪种方式，还是要取决于我们的偏好。

这里先要提及的概念是内存对齐。malloc的每个版本都有aligned\_alloc对应项。malloc函数返回与设备默认对齐的内存，它将返回一个合法的指针和一个有效的对齐方式。但在某些情况下，我们可能更喜欢手动指定对齐的方式，使用aligned\_alloc变量指定所需的对齐方式。如果指定的方式非法，不要期望程序能正常工作!原则上的是2的幂次方。值得注意的是，在许多设备上，分配是最大对齐的，以对应硬件的特性。因此，我们可能要求分配为4字节、8字节、16字节或32字节对齐，但在实际可能会看到更大字节的对齐。

\hspace*{\fill}  %插入空行
图6-2 C风格的USM分配函数
\begin{lstlisting}[caption={}]
// Named Functions
void *malloc_device(size_t size, const device &dev, const context &ctxt);
void *malloc_device(size_t size, const queue &q);
void *aligned_alloc_device(size_t alignment, size_t size,
					const device &dev, const context &ctxt);

void *aligned_alloc_device(size_t alignment, size_t size, const queue &q);

void *malloc_host(size_t size, const context &ctxt);
void *malloc_host(size_t size, const queue &q);
void *aligned_alloc_host(size_t alignment, size_t size, const context
&ctxt);
void *aligned_alloc_host(size_t alignment, size_t size, const queue &q);

void *malloc_shared(size_t size, const device &dev, const context &ctxt);
void *malloc_shared(size_t size, const queue &q);
void *aligned_alloc_shared(size_t alignment, size_t size,
							const device &dev, const context &ctxt);
void *aligned_alloc_shared(size_t alignment, size_t size, const queue &q);

// Single Function
void *malloc(size_t size, const device &dev, const context &ctxt,
			 usm::alloc kind);
void *malloc(size_t size, const queue &q, usm::alloc kind);
void *aligned_alloc(size_t alignment, size_t size,
					const device &dev, const context &ctxt,
					usm::alloc kind);
void *aligned_alloc(size_t alignment, size_t size, const queue &q,
					usm::alloc kind);
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{C++风格的分配方式}

下一个USM分配函数(在图6-3中列出)与第一个非常相似。我们再次拥有分配例程的命名和单函数版本，以及默认和用户指定的对齐版本。不同之处在于，现在的函数是C++模板化函数，它分配类型为T的Count对象并返回类型为T *的指针。可以利用现代C++进行简化，不再需要以字节为单位手动计算分配的总大小，或者将返回的指针强制转换为适当的类型。这也会让代码更紧凑、不容易出错。然而，与C++中的new不同，malloc风格的接口并不为分配的对象调用构造函数——只是分配了足够的字节来适配该类型。

对于使用USM编写的代码来说，这种分配方式是很好的起点。对于大量使用C或C++ malloc的现有C++代码来说，C的方式是很好的起点，我们将在此基础上增加USM的使用。

\hspace*{\fill}  %插入空行
图6-3 C++风格的USM分配函数
\begin{lstlisting}[caption={}]
// Named Functions
template <typename T>
T *malloc_device(size_t Count, const device &Dev, const context &Ctxt); 
template <typename T> 
T *malloc_device(size_t Count, const queue &Q); 
template <typename T>
T *aligned_alloc_device(size_t Alignment, size_t Count, const device &Dev,
						const context &Ctxt); 

template <typename T>
T *aligned_alloc_device(size_t Alignment, size_t Count, const queue &Q); 

template <typename T> T *malloc_host(size_t Count, const context &Ctxt);
template <typename T> T *malloc_host(size_t Count, const queue &Q);
template <typename T>
T *aligned_alloc_host(size_t Alignment, size_t Count, const context &Ctxt);
template <typename T>
T *aligned_alloc_host(size_t Alignment, size_t Count, const queue &Q);、

template <typename T>
T *malloc_shared(size_t Count, const device &Dev, const context &Ctxt);
template <typename T> T *malloc_shared(size_t Count, const queue &Q);
template <typename T>
T *aligned_alloc_shared(size_t Alignment, size_t Count, const device &Dev,
						const context &Ctxt);				
template <typename T>
T *aligned_alloc_shared(size_t Alignment, size_t Count, const queue &Q);

// Single Function
template <typename T>
T *malloc(size_t Count, const device &Dev, const context &Ctxt,
			usm::alloc Kind);
template <typename T> T *malloc(size_t Count, const queue &Q, usm::alloc
Kind);
template <typename T>
T *aligned_alloc(size_t Alignment, size_t Count, const device &Dev,
				const context &Ctxt, usm::alloc Kind);
template <typename T>
T *aligned_alloc(size_t Alignment, size_t Count, const queue &Q,
				usm::alloc Kind);
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{C++分配器}

USM分配的最后一种风格(图6-4)使用了现代C++，这种风格基于C++的allocator接口，该接口定义了直接或间接地在容器(如std::vector)中执行内存分配的对象。如果代码大量使用容器对象，可以向用户隐藏内存分配和回收的细节，简化代码减少出现bug的机会，所以这种分配器风格最为实用。

\hspace*{\fill}  %插入空行
图6-4 C++分配器风格的USM分配函数
\begin{lstlisting}[caption={}]
template <class T, usm::alloc AllocKind, size_t Alignment = 0>
class usm_allocator {
public:
	using value_type = T;
	template <typename U> struct rebind {
		typedef usm_allocator<U, AllocKind, Alignment> other;
	};

	usm_allocator() noexcept = delete;
	usm_allocator(const context &Ctxt, const device &Dev) noexcept;
	usm_allocator(const queue &Q) noexcept;
	usm_allocator(const usm_allocator &Other) noexcept;
	template <class U> 
		usm_allocator(usm_allocator<U, AllocKind, Alignment> const &) noexcept;
		
	T *allocate(size_t NumberOfElements); 
	void deallocate(T *Ptr, size_t Size); 
	
	template <
		usm::alloc AllocT = AllocKind,
		typename std::enable_if<AllocT != usm::alloc::device, int>::type = 0,
		class U, class... ArgTs>
	void construct(U *Ptr, ArgTs &&... Args); 
	
	template <
		usm::alloc AllocT = AllocKind,
		typename std::enable_if<AllocT == usm::alloc::device, int>::type = 0,
		class U, class... ArgTs>
	void construct(U *Ptr, ArgTs &&... Args); 
	
	template <
		usm::alloc AllocT = AllocKind,
		typename std::enable_if<AllocT != usm::alloc::device, int>::type = 0>
	void destroy(T *Ptr);
	
	template <
		usm::alloc AllocT = AllocKind,
		typename std::enable_if<AllocT == usm::alloc::device, int>::type = 0>
	void destroy(T *Ptr);
};
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{释放内存}

无论分配什么，最终都必须释放。USM定义了一个方法来释放malloc或aligned\_malloc函数分配的内存。这个方法还将分配内存的上下文作为一个参数(可以用队列替换上下文)。如果内存是用C++的allocator对象分配，也应该使用该对象来释放内存。

\hspace*{\fill}  %插入空行
图6-5 三种配置方式
\begin{lstlisting}[caption={}]
constexpr int N = 42;

queue Q;

// Allocate N floats

// C-style
float *f1 = static_cast<float*>(malloc_shared(N*sizeof(float),Q));

// C++-style
float *f2 = malloc_shared<float>(N, Q);

// C++-allocator-style
usm_allocator<float, usm::alloc::shared> alloc(Q);
float *f3 = alloc.allocate(N);

// Free our allocations
free(f1, Q.get_context());
free(f2, Q);
alloc.deallocate(f3, N);
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{内存分配示例}

图6-5中，展示了如何使用三种方式进行分配，我们分配N个单精度浮点数作为共享分配内存。第一个分配f1使用C风格的void *返回malloc例程。对于这种分配，我们显式地传递从队列中获得的设备和上下文。

必须将结果强制转换为float*类型。第二个分配f2做了同样的事情，但是使用了C++风格的malloc模板。因为我们将元素的类型float传递给分配示例，所以只需要指定分配多少个float即可，而不需要对结果进行强制转换。还可以使用队列，而不是设备和上下文的形式，完成一段非常简单和紧凑的代码。第三个分配f3使用了USM C++的allocator类，实例化了allocator对象，然后使用该对象执行分配。最后，展示了如何正确地释放分配的内存。


## 6.4 数据管理
了解了如何使用USM内存后，来讨论下如何管理数据。可以将其分为两部分:数据初始化和数据移动。

\hspace*{\fill}  %插入空行
\textbf{初始化}

数据初始化关注的是对内存执行计算前内存的填充值，常见初始化是使用零填充。要对使用USM内存进行初始化，可以通过多种方式来实现。最直接的就是写一个内核来做初始化，如果数据集特别大，或者需要复杂的计算，这种方法没问题。也可以实现为遍历所有元素的循环，将每个元素设置为0，这种方法存在一个问题。循环可以很好地用于主机和共享分配的内存，因为可以在主机上访问。但在主机上不能访问设备分配，主机代码中的循环将不能对设备内存进行写入。这就有了第三种选择。

memset函数可以用来实现这个初始化模式。USM提供了一个memset函数，有三个参数:要设置的内存指针，要设置的模式，以及要设置为该模式的字节数。与主机的循环不同，memset是并行发生的。

虽然memset是一个有用的操作，但只允许指定一个模式来填充。USM还提供了fill方法，允许用任意模式填充内存。给它创建一个int型模板，然后用数字“42”填充内存。与memset类似，fill接受三个参数:要填充的内存的指针，要填充的值，以及希望将该值写入内存的数量。

\hspace*{\fill}  %插入空行
\textbf{数据移动}

数据移动可能是USM的重点。如果正确的数据没有在正确的时间出现在正确的地点，程序将产生不正确的结果。USM定义了两种用来管理数据的策略:显式和隐式。使用策略的选择与硬件支持，或使用的USM类型有关。

\hspace*{\fill}  %插入空行
\textbf{显式}

USM提供的第一个策略是显式数据移动(图6-6)，必须显式地在主机和设备之间复制数据。可以通过调用memcpy完成，该方法可以在处理程序和队列类上找到。memcpy方法有三个参数:指向目标内存的指针，指向源内存的指针，以及主机和设备之间复制的字节数。不需要指定复制发生的方向——这在源指针和目标指针中是隐式确定的。

显式数据移动最常见的用法是使用USM对设备内存中的数据进行复制，因为设备端内存在主机上不可访问。此外，这可能会造成错误:可能会忽略复制，不正确的数据量可能被复制，或者源或目标指针可能不正确。

然而，显式数据移动也有优点:完全控制数据移动。某些应用程序中，控制复制数据的数量和复制数据的时间，对于获得最佳性能非常重要。理想情况下，可以将计算与数据移动重叠，确保硬件高效率运行。

其他的USM类型，不论是host，还是shared，都可以在主机和设备端访问，不需要显式地复制到设备。这就引出了USM中数据移动的另一种策略。

\hspace*{\fill}  %插入空行
图6-6 USM显式移动数据
\begin{lstlisting}[caption={}]
constexpr int N = 42;

queue Q;

std::array<int,N> host_array;
int *device_array = malloc_device<int>(N, Q);
for (int i = 0; i < N; i++)
	host_array[i] = N;

Q.submit([&](handler& h) {
	// copy hostArray to deviceArray
	h.memcpy(device_array, &host_array[0], N * sizeof(int));
});

Q.wait(); // needed for now (we learn a better way later)

Q.submit([&](handler& h) {
	h.parallel_for(N, [=](id<1> i) {
		device_array[i]++;
	});
});

Q.wait(); // needed for now (we learn a better way later)

Q.submit([&](handler& h) {
	// copy deviceArray back to hostArray
	h.memcpy(&host_array[0], device_array, N * sizeof(int));
});

Q.wait(); // needed for now (we learn a better way later)

free(device_array, Q);
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{隐式}

USM提供的第二种策略是隐式数据移动(示例用法如图6-7所示)。这个策略中，数据移动是隐式发生的，不需要memcpy，因为可以通过USM指针直接访问数据。而系统的任务是确保数据在使用时，在正确的位置上可用。

对于主机内存，可能会争论是否真的进行了数据移动。根据定义，分配的内存始终指向主机内存，因此给定的主机指针表示的内存不能存储在设备上。但当在设备上访问主机内存时，数据移动就会发生。不是将内存迁移到设备，而是通过适当的接口将读或写的值传输到内核中。这对于数据不需要驻留在设备上的流内核很有用。

隐式数据移动主要与USM共享内存有关。这种类型的内存可以在主机和设备上访问，并且可以在主机和设备之间迁移。这种迁移是自动进行的，或者是隐式地进行的，只需访问不同位置的数据即可。接下来，讨论为共享内存进行数据迁移时需要考虑的几个问题。

\hspace*{\fill}  %插入空行
图6-7 USM隐式数据移动
\begin{lstlisting}[caption={}]
constexpr int N = 42;

queue Q;

int* host_array = malloc_host<int>(N, Q);
int* shared_array = malloc_shared<int>(N, Q);
for (int i = 0; i < N; i++)
	host_array[i] = i;
	
Q.submit([&](handler& h) {
	h.parallel_for(N, [=](id<1> i) {
		// access sharedArray and hostArray on device
		shared_array[i] = host_array[i] + 1;
	});
});

Q.wait();

free(shared_array, Q);
free(host_array, Q);
\end{lstlisting}

\hspace*{\fill}  %插入空行
\textbf{迁移}

通过显式数据移动，可以控制发生多少数据移动。使用隐式数据移动，系统可处理这一问题，但可能没有那么高效。DPC++运行时不是oracle——不能预测应用将访问什么数据。此外，指针分析对于编译器来说非常困难，可能无法准确地分析和识别内核中可能使用的每个内存分配。因此，隐式数据移动机制的实现，可能会根据支持USM设备的功能做出不同的决策，这既影响共享内存的使用方式，也影响了它们的执行方式。

如果设备能力非常强，能够根据需要迁移内存。这种情况下，数据移动将在主机或设备试图访问数据不存在的内存位置时发生。按需获取数据极大地简化了编程，可以在任何地方访问USM共享内存，并且可以正常工作。如果设备不支持按需迁移(第12章解释了如何查询设备的功能)，仍然能够保证相同的语义，并对共享指针的使用方式进行限制。

限制形式的USM共享内存会确定何时何地可以访问共享neicu8n，以及共享分配的大小。如果设备不能按需迁移内存，则运行时必须保守，并假定内核可以访问其设备附加内存中的任何分配。这会带来两种后果。

首先，主机和设备不该同时访问共享内存，程序应该以阶段替代访问。主机可以访问内存数据，然后内核可以使用该数据进行计算，最后主机读取结果。

如果没有这个限制，主机可以访问内核的不同分配。这种并发访问通常发生在设备内存页上。主机可以访问一个内存页，而设备可以访问另一个内存页。第19章将介绍原子访问相同的数据块。

这种受限的共享内存形式的第二个后果是，受到设备内存总量的限制。如果设备不能按需迁移内存，则无法将数据迁移到主机，为不同的数据腾出空间。如果设备支持按需迁移，则可能会超量使用内存，从而允许内核计算超过设备内存通常包含的数据，而这种灵活性可能会因为数据移动，产生性能损失。

\hspace*{\fill}  %插入空行
\textbf{细粒度控制}

当设备支持按需迁移共享内存时，访问内存位置上没有相应数据时，需要进行数据移动。这时，内核在等待数据移动完成时可能会停止。接下来执行的语句可能会产生更多的数据移动，并给内核执行带来更多的延迟。

DPC++提供了一种修改自动迁移机制性能的方法。通过定义两个函数来做到这一点:prefetch和mem\_advise。图6-8展示了每种方法，这些函数向运行时提供了内核如何访问数据的方式，以便运行时选择在内核访问数据之前开始移动数据。请注意，这个例子直接在队列对象上调用parallel\_for的队列快捷方法，而不是在传递给submit(命令组)一个Lambda调用。

\hspace*{\fill}  %插入空行
图6-8 通过prefetch和mem\_advise进行细粒度控制
\begin{lstlisting}[caption={}]
// Appropriate values depend on your HW
constexpr int BLOCK_SIZE = 42;
constexpr int NUM_BLOCKS = 2500;
constexpr int N = NUM_BLOCKS * BLOCK_SIZE;

queue Q;
int *data = malloc_shared<int>(N, Q);
int *read_only_data = malloc_shared<int>(BLOCK_SIZE, Q);

// Never updated after initialization
for (int i = 0; i < BLOCK_SIZE; i++)
	read_only_data[i] = i;
	
// Mark this data as "read only" so the runtime can copy it
// to the device instead of migrating it from the host.
// Real values will be documented by your DPC++ backend.
int HW_SPECIFIC_ADVICE_RO = 0;

Q.mem_advise(read_only_data, BLOCK_SIZE, HW_SPECIFIC_ADVICE_RO);

event e = Q.prefetch(data, BLOCK_SIZE);

for (int b = 0; b < NUM_BLOCKS; b++) {
	Q.parallel_for(range{BLOCK_SIZE}, e, [=](id<1> i) {
		data[b * BLOCK_SIZE + i] += data[i];
	});
	if ((b + 1) < NUM_BLOCKS) {
		// Prefetch next block
		e = Q.prefetch(data + (b + 1) * BLOCK_SIZE, BLOCK_SIZE);
	}
}

Q.wait();

free(data, Q);
free(read_only_data, Q);
\end{lstlisting}

最简单的方法是调用预取(prefetch)。此函数作为处理程序或队列类的成员函数，接受指针和字节数。这可以通知运行时某些数据将在设备上使用，以便能够及时地迁移。理想情况下，应该尽早了解这些信息，这样当内核访问数据时，数据就已经驻留在设备上了，从而消除之前所说的延迟。

DPC++提供的另一个函数是mem\_advise，这个函数可以确定内核中可以使用哪些特定于设备的内存。这样的话，当数据只在内核中读取，而不是写入，系统就可以意识到这个操作可以复制设备上的数据，这样在内核完成后就不需要更新主机的数据。但是，传递给mem\_advise的参数是特定于设备的，所以使用此函数之前，请查阅硬件供应商的文档。



## 6.5 查询

最后，并不是所有设备都支持USM的特性。如果希望程序可以在不同的设备上移植，不应该假设所有的USM功能都可用。USM的特性可以查询，这些查询可以分为两类:指针查询和设备功能查询。图6-9显示了每种方法的简单使用方法。

USM中的指针查询需要回答两个问题。第一个问题是“这个指针指向哪种USM分配类型?”get\_pointer\_type函数接受一个指针和DPC++上下文，并返回一个usm::alloc类型的结果，可以有四种可能的值:host、device、shared或unknown。第二个问题是“这个USM指针分配给了什么设备?”可以向函数get\_pointer\_device传递一个指针和一个上下文，并获得一个设备对象。这主要用于设备或共享USM内存，对主机内存没什么意义。

USM提供的第二种查询，关系到设备的性能。USM扩展了可以通过在设备对象上调用get\_info来查询的设备信息描述符列表。这些查询可用于测试设备支持哪种USM分配类型。此外，可以查询设备上的共享内训是否按照本章前面描述的方式进行了限制。完整的查询列表如图6-10所示。第12章中，会更详细地了解查询机制。

\hspace*{\fill}  %插入空行
图6-9 查询USM指针和设备
\begin{lstlisting}[caption={}]
constexpr int N = 42;

template <typename T> void foo(T data, id<1> i) { data[i] = N; }

queue Q;
auto dev = Q.get_device();
auto ctxt = Q.get_context();
bool usm_shared = dev.get_info<dinfo::usm_shared_allocations>();
bool usm_device = dev.get_info<dinfo::usm_device_allocations>();
bool use_USM = usm_shared || usm_device;

if (use_USM) {
	int *data;
	if (usm_shared)
		data = malloc_shared<int>(N, Q);
	else /* use device allocations */
		data = malloc_device<int>(N, Q);
		
	std::cout << "Using USM with "
			<< ((get_pointer_type(data, ctxt) == usm::alloc::shared)
			? "shared"
			: "device")
			<< " allocations on "
			<< get_pointer_device(data, ctxt).get_info<dinfo::name>()
			<< "\n";
			
	Q.parallel_for(N, [=](id<1> i) { foo(data, i); });
	Q.wait();
	free(data, Q);
} else /* use buffers */ {
	buffer<int, 1> data{range{N}};
	Q.submit([&](handler &h) {
		accessor a(data, h);
		h.parallel_for(N, [=](id<1> i) {
			foo(a, i); });
	});
	Q.wait();
}
\end{lstlisting}

\hspace*{\fill}  %插入空行
图6-10 USM设备信息描述符
\begin{table}[H]
	\begin{tabular}{|l|l|p{6cm}|}
		\hline
		设备描述符                                  & 类型 & 描述                                                                                   \\ \hline
		info::device::usm\_device\_allocations             & bool & 如果该设备支持设备分配，则返回true                                       \\ \hline
		info::device::usm\_host\_allocations               & bool & 如果设备可以访问主机分配，则返回true                                       \\ \hline
		info::device::usm\_shared\_allocations             & bool & 如果该设备支持共享分配，则返回true                                       \\ \hline
		info::device::usm\_restricted\_shared\_allocations & bool & 如果共享分配受本章描述的限制约束，则返回true \\ \hline
	\end{tabular}
\end{table}


## 6.6 总结

本章中，描述了统一共享内存，一种基于指针的数据管理策略。介绍了USM的三种类型的内存分配。讨论了使用USM分配和释放内存的所有不同方式，以及数据移动可以由开发者显式控制进行设备分配，也可以由系统隐式控制共享内存。最后，讨论了如何查询设备支持的不同USM功能，以及如何在程序中查询关于USM指针的信息。

因为还没有在本书中详细讨论同步，所以在后面的章节中会讨论调度、通信和同步的时候会有更多关于USM的内容。将在第8、9和19章中继续讨论USM。

下一章中，我们将介绍数据管理的第二种策略:缓冲区。