This chapter discussed how work-items in a group may communicate and cooperate to improve the performance of some types of kernels.\par

We first discussed how ND-range kernels and hierarchical kernels support grouping work-items into work-groups. We discussed how grouping work-items into work-groups changes the parallel execution model, guaranteeing that the work-items in a work-group execute concurrently and enabling communication and synchronization.\par

Next, we discussed how the work-items in a work-group may synchronize using barriers and how barriers are expressed explicitly for NDrange kernels or implicitly between work-group and work-item scopes for hierarchical kernels. We also discussed how communication between workitems in a work-group can be performed via work-group local memory, both to simplify kernels and to improve performance, and we discussed how work-group local memory is represented using local accessors for ND-range kernels or allocations at work-group scope for hierarchical kernels.\par

We discussed how work-groups in ND-range kernels may be further divided into sub-groupings of work-items, where the sub-groups of workitems may support additional communication patterns or scheduling guarantees.\par

For both work-groups and sub-groups, we discussed how common communication patterns may be expressed and accelerated through use of collective functions.\par

The concepts in this chapter are an important foundation for understanding the common parallel patterns described in Chapter 14 and for understanding how to optimize for specific devices in Chapters 15, 16, and 17.\par


\newpage